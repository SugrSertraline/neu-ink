"""
å¤§æ¨¡å‹å·¥å…·ç±»
æ”¯æŒå¤šç§å¤§æ¨¡å‹è°ƒç”¨ï¼Œç›®å‰é›†æˆ GLM-4.6 æ¨¡å‹
"""

import os
import sys
import json
import requests
import locale
from typing import Dict, Any, Optional, List
from enum import Enum

# è®¾ç½®ç¼–ç ä¸ºUTF-8ä»¥å¤„ç†Unicodeå­—ç¬¦
if sys.platform.startswith('win'):
    # åœ¨Windowsä¸‹è®¾ç½®æ§åˆ¶å°è¾“å‡ºç¼–ç 
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())
    
    # è®¾ç½®é»˜è®¤ç¼–ç 
    if hasattr(sys, 'setdefaultencoding'):
        sys.setdefaultencoding('utf-8')
        
import logging

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('neuink_llm.log', encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

logger = logging.getLogger(__name__)

# å®‰å…¨çš„æ—¥å¿—æ‰“å°å‡½æ•°
def safe_print(*args, **kwargs):
    """å®‰å…¨çš„æ‰“å°å‡½æ•°ï¼Œé¿å…ç¼–ç é”™è¯¯ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶å’Œæ§åˆ¶å°"""
    try:
        # æ„å»ºæ¶ˆæ¯å­—ç¬¦ä¸²
        message = ' '.join(str(arg) for arg in args)
        
        # è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆUTF-8ç¼–ç ï¼‰
        logger.info(message)
        
        # å°è¯•è¾“å‡ºåˆ°æ§åˆ¶å°
        try:
            print(message, **kwargs)
        except UnicodeEncodeError:
            # Windowsæ§åˆ¶å°ç¼–ç é”™è¯¯å¤„ç†
            try:
                # å°è¯•ä½¿ç”¨Windowsæ§åˆ¶å°å…¼å®¹çš„ç¼–ç 
                print(message.encode('gbk', errors='replace').decode('gbk'), **kwargs)
            except:
                # æœ€åçš„å…œåº•æ–¹æ¡ˆï¼šç§»é™¤éASCIIå­—ç¬¦
                safe_message = ''.join(char if ord(char) < 128 else '?' for char in message)
                print(safe_message, **kwargs)
                
    except Exception as e:
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè‡³å°‘è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
        try:
            logger.error(f"safe_print failed: {e}")
        except:
            pass  # é¿å…é€’å½’é”™è¯¯

class LLMModel(Enum):
    """æ”¯æŒçš„å¤§æ¨¡å‹æšä¸¾"""
    GLM_4_6 = "glm-4.6"
    GLM_4_5 = "glm-4.5"
    GLM_4_PLUS = "glm-4-plus"
    # æœªæ¥å¯ä»¥æ‰©å±•å…¶ä»–æ¨¡å‹
    # GPT_4 = "gpt-4"
    # CLAUDE_3 = "claude-3"

class LLMUtils:
    """å¤§æ¨¡å‹å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®"""
        self.glm_api_key = os.getenv('GLM_API_KEY')
        self.glm_base_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        safe_print(f"GLM API Key çŠ¶æ€: {'[å·²é…ç½®]' if self.glm_api_key and self.glm_api_key != 'your_glm_api_key_here' else '[æœªé…ç½®æˆ–ä¸ºå ä½ç¬¦]'}")
        safe_print(f"[APIç«¯ç‚¹]: {self.glm_base_url}")
        
    def call_llm(
        self,
        messages: List[Dict[str, str]],
        model: LLMModel = LLMModel.GLM_4_6,
        temperature: float = 0.1,
        max_tokens: int = 100000,
        stream: bool = False,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨å¤§æ¨¡å‹æ¥å£
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": "..."}]
            model: ä½¿ç”¨çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–æ¨¡å‹ç‰¹å®šå‚æ•°
            
        Returns:
            æ¨¡å‹å“åº”ç»“æœæˆ– Noneï¼ˆå¦‚æœå‡ºé”™ï¼‰
        """
        if model == LLMModel.GLM_4_6:
            return self._call_glm(messages, temperature, max_tokens, stream, **kwargs)
        elif model == LLMModel.GLM_4_5:
            return self._call_glm(messages, temperature, max_tokens, stream, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}")
    
    def _call_glm(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        stream: bool,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ GLM æ¨¡å‹
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            GLM å“åº”ç»“æœæˆ– None
        """
        safe_print("å¼€å§‹è°ƒç”¨GLM API")
        safe_print(f"è¯·æ±‚æ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        if not self.glm_api_key:
            safe_print("é”™è¯¯ï¼šæœªè®¾ç½® GLM_API_KEY ç¯å¢ƒå˜é‡")
            return None
            
        # ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹åç§°
        payload = {
            "model": LLMModel.GLM_4_6.value,  # ä¿®å¤ï¼šä½¿ç”¨ glm-4.6
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream,
            **kwargs
        }
        
        safe_print(f"æ¨¡å‹: {payload['model']}")
        safe_print(f"æ¸©åº¦: {payload['temperature']}")
        safe_print(f"æœ€å¤§Tokenæ•°: {payload['max_tokens']}")
        safe_print("æ¶ˆæ¯å†…å®¹é¢„è§ˆ:")
        for i, msg in enumerate(messages):
            safe_print(f"  {i+1}. [{msg['role']}] {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}")
        
        # æ£€æŸ¥APIå¯†é’¥é•¿åº¦å’Œæ ¼å¼
        if len(self.glm_api_key) < 20:
            safe_print(f"è­¦å‘Šï¼šAPIå¯†é’¥é•¿åº¦å¼‚å¸¸ ({len(self.glm_api_key)} å­—ç¬¦)")
        
        headers = {
            "Authorization": f"Bearer {self.glm_api_key}",  # æ˜¾ç¤ºå®Œæ•´å¯†é’¥ä¾¿äºè°ƒè¯•
            "Content-Type": "application/json"
        }
        
        try:
            safe_print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°GLM API...")
            safe_print(f"APIç«¯ç‚¹: {self.glm_base_url}")
            
            # è¯¦ç»†è®°å½•è¯·æ±‚ä½“
            safe_print("è¯·æ±‚ä½“é¢„è§ˆ:")
            safe_print(f"  model: {payload['model']}")
            safe_print(f"  temperature: {payload['temperature']}")
            safe_print(f"  max_tokens: {payload['max_tokens']}")
            safe_print(f"  stream: {payload['stream']}")
            
            response = requests.post(
                self.glm_base_url,
                json=payload,
                headers=headers,
                timeout=180  # 60ç§’è¶…æ—¶
            )
            
            safe_print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            safe_print(f"å“åº”å¤´: {dict(response.headers)}")
            
            # å¦‚æœæ˜¯401é”™è¯¯ï¼Œæ˜¾ç¤ºå“åº”å†…å®¹
            if response.status_code == 401:
                try:
                    error_response = response.json()
                    safe_print(f"401é”™è¯¯è¯¦æƒ…: {error_response}")
                except:
                    safe_print(f"401é”™è¯¯å“åº”å†…å®¹: {response.text[:500]}")
            
            response.raise_for_status()
            
            result = response.json()
            safe_print("GLM APIè°ƒç”¨æˆåŠŸ")
            
            if 'choices' in result:
                safe_print(f"è¿”å›é€‰æ‹©æ•°é‡: {len(result['choices'])}")
                if result['choices']:
                    content = result['choices'][0]['message']['content']
                    safe_print(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                    safe_print(f"å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}{'...' if len(content) > 200 else ''}")
            
            return result
            
        except requests.exceptions.RequestException as e:
            safe_print(f"GLM API è°ƒç”¨å¤±è´¥: {e}")
            if hasattr(e, 'response'):
                safe_print(f"è¯·æ±‚è¯¦æƒ…: çŠ¶æ€ç  {e.response.status_code}")
                try:
                    error_content = e.response.json()
                    safe_print(f"é”™è¯¯è¯¦æƒ…: {error_content}")
                except:
                    safe_print(f"é”™è¯¯å“åº”: {e.response.text[:500]}")
            else:
                safe_print(f"è¯·æ±‚è¯¦æƒ…: æ— å“åº”å¯¹è±¡")
            return None
        except json.JSONDecodeError as e:
            safe_print(f"GLM API å“åº”è§£æå¤±è´¥: {e}")
            return None
    
    def extract_paper_metadata(self, text: str) -> Dict[str, Any]:
        """
        ä»…ä½¿ç”¨ LLM æå–è®ºæ–‡ä¿¡æ¯ï¼›ä»»ä½•é”™è¯¯éƒ½ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸åšå…œåº•è§£æã€‚
        """
        safe_print("=" * 60)
        safe_print("å¼€å§‹è§£æè®ºæ–‡æ–‡æœ¬ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼šæ— å…œåº•ï¼‰")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        safe_print("=" * 60)

        # 1) å¿…é¡»æœ‰å¯ç”¨çš„ API Key
        if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
            raise RuntimeError("LLM ä¸å¯ç”¨ï¼šæœªé…ç½®æˆ–ä½¿ç”¨äº†å ä½ GLM_API_KEY")

        # 2) åªèµ° LLMï¼›å¤±è´¥å³æŠ›é”™
        try:
            result = self._extract_with_llm(text)
        except Exception as e:
            # é€ä¼ ä¸€å±‚ï¼Œç»™ä¸Šæ¸¸/HTTP å±‚è¿”å›æ¸…æ™°çš„ message
            raise RuntimeError(f"LLM è§£æå¤±è´¥: {e}")

        if not result:
            raise RuntimeError("LLM è¿”å›ç©ºç»“æœ")

        return result

    def _extract_with_llm(self, text: str) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨LLMè§£ææ–‡æœ¬"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡è§£æåŠ©æ‰‹ã€‚è¯·ä»ç»™å®šçš„è®ºæ–‡æ–‡æœ¬ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

1. metadataï¼ˆå…ƒæ•°æ®ï¼‰:
   - title: è®ºæ–‡æ ‡é¢˜
   - authors: ä½œè€…åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"name": "ä½œè€…å§“å", "affiliation": "æ‰€å±æœºæ„"}]
   - year: å‘è¡¨å¹´ä»½
   - journal: æœŸåˆŠåç§°
   - articleType: æ–‡ç« ç±»å‹ï¼ˆå¦‚ï¼šjournal, conference, preprintï¼‰
   - doi: DOI
   - tags: ç›¸å…³æ ‡ç­¾

2. abstractï¼ˆæ‘˜è¦ï¼‰:
   - zh: ä¸­æ–‡æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
   - en: è‹±æ–‡æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰

3. keywordsï¼ˆå…³é”®è¯ï¼‰:
   - å…³é”®è¯åˆ—è¡¨

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå¦‚æœæŸäº›ä¿¡æ¯æ— æ³•ä»æ–‡æœ¬ä¸­æå–ï¼Œè¯·è®¾ç½®ä¸ºnullæˆ–ç©ºæ•°ç»„ã€‚"""

        user_prompt = f"è¯·åˆ†æä»¥ä¸‹è®ºæ–‡æ–‡æœ¬ï¼Œæå–metadata, abstractå’Œkeywordsï¼š\n\n{text[:40000]}"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            # ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°è®¾ç½®
            response = self.call_llm(messages, temperature=0.6)  # ä½¿ç”¨0.6çš„æ¸©åº¦ï¼Œä¸ç¤ºä¾‹ä¸€è‡´
            
            if not response or 'choices' not in response:
                safe_print("GLM å“åº”æ ¼å¼é”™è¯¯")
                return None
                
            content = response['choices'][0]['message']['content']
            
            # å°è¯•è§£æ JSON
            try:
                # æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—ä¸­ï¼‰
                if '```json' in content:
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                elif '```' in content:
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                
                parsed_data = json.loads(content)
                return parsed_data
                
            except json.JSONDecodeError as e:
                safe_print(f"GLM è¿”å›çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {e}")
                safe_print(f"åŸå§‹å†…å®¹: {content}")
                return None
                
        except Exception as e:
            safe_print(f"æå–è®ºæ–‡å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_with_simple_parsing(self, text: str) -> Dict[str, Any]:
        """ç®€å•çš„æ–‡æœ¬è§£ææ–¹æ³•ï¼Œå½“LLMä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        import re
        
        safe_print("å¼€å§‹ç®€å•æ–‡æœ¬è§£æ")
        safe_print(f"æ–‡æœ¬è¡Œæ•°: {len(text.split(chr(10)))}")
        
        lines = text.split('\n')
        
        # æ”¹è¿›çš„æ ‡é¢˜æå–é€»è¾‘
        title = "æœªå‘½åè®ºæ–‡"
        safe_print("å¼€å§‹æå–æ ‡é¢˜ (æ£€æŸ¥å‰15è¡Œ)")
        for i, line in enumerate(lines[:15]):  # æ£€æŸ¥å‰15è¡Œ
            line = line.strip()
            # æ›´ä¸¥æ ¼çš„æ ‡é¢˜è¿‡æ»¤æ¡ä»¶
            if (len(line) > 10 and
                not line.startswith('#') and
                not line.startswith('http') and
                not any(keyword in line.lower() for keyword in ['abstract', 'introduction', 'keywords', 'doi:', 'author', 'authors', 'by', 'email', 'correspondence']) and
                # æ ‡é¢˜é€šå¸¸ä¸åŒ…å«å¤šä¸ªé€—å·åˆ†éš”çš„åå­—
                not re.search(r'\d+[,Ã—]?\d+[,Ã—]?\*?[,Ã—]?\$?\$?\{.*\}', line) and  # è¿‡æ»¤æ‰åŒ…å«ä¸Šæ ‡è„šæ³¨çš„è¡Œ
                # æ ‡é¢˜é€šå¸¸ä¸åŒ…å«é‚®ç®±æˆ–è”ç³»æ–¹å¼
                not '@' in line and not '.edu' in line and not '.org' in line):
                
                title = line
                safe_print(f"æå–åˆ°æ ‡é¢˜: {title} (æ¥è‡ªç¬¬{i+1}è¡Œ)")
                break
        
        # æ”¹è¿›çš„ä½œè€…æå–é€»è¾‘
        authors = []
        safe_print("å¼€å§‹æå–ä½œè€…ä¿¡æ¯")
        authors_found = False
        
        # åœ¨æ ‡é¢˜é™„è¿‘å¯»æ‰¾ä½œè€…ä¿¡æ¯
        title_line_index = -1
        for i, line in enumerate(lines[:15]):
            if line.strip() == title:
                title_line_index = i
                break
        
        if title_line_index >= 0:
            # æ£€æŸ¥æ ‡é¢˜åçš„å‡ è¡Œ
            for i in range(title_line_index + 1, min(title_line_index + 5, len(lines))):
                line = lines[i].strip()
                if line and not line.startswith('#'):
                    # æ£€æŸ¥æ˜¯å¦åƒä½œè€…è¡Œï¼ˆåŒ…å«å¤šä¸ªå§“åå’Œå¯èƒ½çš„æœºæ„ä¿¡æ¯ï¼‰
                    if (re.search(r'[A-Za-z][A-Za-z\s,.-]+\s[A-Za-z]', line) and
                        not 'abstract' in line.lower() and
                        not len(line) > 200):  # ä½œè€…è¡Œé€šå¸¸ä¸ä¼šå¤ªé•¿
                        
                        safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°ä½œè€…ä¿¡æ¯: {line}")
                        
                        # ä½¿ç”¨æ›´ç²¾ç¡®çš„ä½œè€…ååˆ†å‰²
                        # å»é™¤å¸¸è§çš„æœºæ„ä¿¡æ¯
                        clean_line = re.sub(r'\([^)]*\)', '', line)  # å»é™¤æ‹¬å·å†…å®¹
                        clean_line = re.sub(r'\d+[,Ã—]?\d+[,Ã—]?\*?[,Ã—]?', '', clean_line)  # å»é™¤ä¸Šæ ‡
                        
                        # æŒ‰å¸¸è§åˆ†éš”ç¬¦åˆ†å‰²
                        author_parts = re.split(r'[,\s]+and\s+|\s+and\s+|,\s*|;\s*|;', clean_line)
                        for part in author_parts:
                            part = part.strip()
                            # è¿‡æ»¤æ‰æ˜æ˜¾çš„éå§“åå†…å®¹
                            if (part and
                                len(part) > 2 and
                                len(part) < 50 and
                                not re.match(r'^\d+$', part) and  # ä¸æ˜¯çº¯æ•°å­—
                                not '@' in part and  # ä¸æ˜¯é‚®ç®±
                                not any(keyword in part.lower() for keyword in ['university', 'institute', 'department', 'school', 'college'])):
                                authors.append({"name": part, "affiliation": ""})
                                safe_print(f"  æå–ä½œè€…: {part}")
                        authors_found = True
                        break
        
        # æå–å¹´ä»½ - ä¼˜å…ˆåœ¨ç‰¹å®šä½ç½®æŸ¥æ‰¾
        year = None
        safe_print("å¼€å§‹æå–å¹´ä»½")
        
        # 1. åœ¨æ ‡é¢˜é™„è¿‘æŸ¥æ‰¾å¹´ä»½
        for i in range(max(0, title_line_index - 3), min(len(lines), title_line_index + 10)):
            year_match = re.search(r'\b(19|20)\d{2}\b', lines[i])
            if year_match:
                year = int(year_match.group())
                safe_print(f"æå–åˆ°å¹´ä»½: {year} (æ¥è‡ªç¬¬{i+1}è¡Œ)")
                break
        
        # å¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°ï¼Œæœç´¢æ•´ä¸ªæ–‡æœ¬
        if not year:
            year_match = re.search(r'\b(19|20)\d{2}\b', text)
            if year_match:
                year = int(year_match.group())
                safe_print(f"æå–åˆ°å¹´ä»½: {year} (å…¨æ–‡æœç´¢)")
        
        # æ”¹è¿›çš„æ‘˜è¦æå–é€»è¾‘
        abstract_text = ""
        abstract_found = False
        safe_print("å¼€å§‹æå–æ‘˜è¦")
        
        for i, line in enumerate(lines):
            line_lower = line.lower().strip()
            
            # å¯»æ‰¾æ‘˜è¦å¼€å§‹æ ‡è®°
            if (('abstract' in line_lower and ':' not in line_lower) or
                ('summary' in line_lower and ':' not in line_lower) or
                ('we present' in line_lower and len(line_lower) < 100)):
                
                abstract_found = True
                safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°æ‘˜è¦å¼€å§‹: {line.strip()}")
                
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦å¼€å§‹çœŸæ­£çš„æ‘˜è¦å†…å®¹
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if next_line and len(next_line) > 50:  # æ‘˜è¦é€šå¸¸æ¯”è¾ƒé•¿
                        abstract_text = next_line + " "
                        if len(abstract_text) < 300:  # å¦‚æœè¿˜ä¸å¤Ÿé•¿ï¼Œç»§ç»­è¯»å–
                            for j in range(i + 2, min(i + 10, len(lines))):
                                if lines[j].strip() and not lines[j].lower().startswith(('keywords', 'index terms', '1.', 'introduction')):
                                    abstract_text += lines[j] + " "
                                else:
                                    break
                        safe_print(f"æ‘˜è¦æå–å†…å®¹: {abstract_text[:200]}...")
                break
        
        # æå–DOI
        doi = None
        safe_print("å¼€å§‹æå–DOI")
        
        # åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­æœç´¢DOI
        doi_patterns = [
            r'doi[:\s]*(10\.\d+[^\s\n]*)',
            r'DOI[:\s]*(10\.\d+[^\s\n]*)',
            r'10\.\d+[/\w\-.,;()\s]*',
        ]
        
        for pattern in doi_patterns:
            doi_match = re.search(pattern, text, re.IGNORECASE)
            if doi_match:
                doi = doi_match.group(1) if '10.' in doi_match.group() else doi_match.group()
                # æ¸…ç†DOI
                doi = re.sub(r'[.,;]+$', '', doi)  # å»é™¤æœ«å°¾çš„æ ‡ç‚¹
                safe_print(f"æå–åˆ°DOI: {doi}")
                break
        
        # æ”¹è¿›çš„å…³é”®è¯æå–é€»è¾‘
        keywords = []
        safe_print("å¼€å§‹æå–å…³é”®è¯")
        
        for i, line in enumerate(lines):
            line_lower = line.lower().strip()
            
            # å¯»æ‰¾å…³é”®è¯æ ‡è®°
            if (('keywords' in line_lower and ':' not in line_lower) or
                ('index terms' in line_lower) or
                (line_lower.startswith('keywords') or line_lower.startswith('index terms'))):
                
                safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°å…³é”®è¯: {line.strip()}")
                
                # æå–å…³é”®è¯å†…å®¹
                keywords_text = line
                if ':' in keywords_text:
                    keywords_text = keywords_text.split(':', 1)[1]
                
                # æ¸…ç†å¹¶åˆ†å‰²å…³é”®è¯
                keywords_text = re.sub(r'[â€”â€“\-]+', ',', keywords_text)  # æ›¿æ¢å„ç§ç ´æŠ˜å·
                kw_list = re.split(r'[,;]+', keywords_text)
                
                extracted_keywords = []
                for kw in kw_list:
                    kw = kw.strip()
                    # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯å…³é”®è¯çš„å†…å®¹
                    if (kw and
                        len(kw) > 2 and
                        len(kw) < 30 and
                        not re.match(r'^\d+$', kw) and  # ä¸æ˜¯çº¯æ•°å­—
                        not kw.lower().startswith(('and', 'or', 'the', 'a', 'an'))):
                        extracted_keywords.append(kw)
                
                keywords.extend(extracted_keywords)
                safe_print(f"  æå–å…³é”®è¯: {extracted_keywords}")
                break
        
        # æœŸåˆŠç±»å‹æ¨æ–­
        article_type = "journal"
        if any(keyword in text.lower() for keyword in ['conference', 'proceedings', 'workshop']):
            article_type = "conference"
        elif any(keyword in text.lower() for keyword in ['preprint', 'arxiv']):
            article_type = "preprint"
        
        result = {
            "metadata": {
                "title": title,
                "authors": authors,
                "year": year,
                "journal": "",
                "articleType": article_type,
                "doi": doi,
                "tags": []
            },
            "abstract": {
                "zh": None,  # ç®€å•è§£æä¸åŒºåˆ†è¯­è¨€
                "en": abstract_text.strip() if abstract_text.strip() else None
            },
            "keywords": keywords[:10]  # é™åˆ¶å…³é”®è¯æ•°é‡
        }
        
        safe_print("ç®€å•æ–‡æœ¬è§£æå®Œæˆ")
        safe_print("è§£æç»“æœæ‘˜è¦:")
        safe_print(f"  æ ‡é¢˜: {result['metadata']['title']}")
        safe_print(f"  ä½œè€…æ•°é‡: {len(result['metadata']['authors'])}")
        if result['metadata']['authors']:
            safe_print(f"  ä½œè€…åˆ—è¡¨: {[author['name'] for author in result['metadata']['authors']]}")
        safe_print(f"  å¹´ä»½: {result['metadata']['year']}")
        safe_print(f"  æ‘˜è¦é•¿åº¦: {len(result['abstract']['en'] or '')} å­—ç¬¦")
        safe_print(f"  DOI: {result['metadata']['doi']}")
        safe_print(f"  å…³é”®è¯æ•°é‡: {len(result['keywords'])}")
        safe_print(f"  æ–‡ç« ç±»å‹: {result['metadata']['articleType']}")
        
        return result
    
    def simple_text_chat(self, user_message: str, system_message: str = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚") -> Optional[str]:
        """
        ç®€å•çš„æ–‡æœ¬å¯¹è¯æ¥å£
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            system_message: ç³»ç»Ÿæ¶ˆæ¯
            
        Returns:
            æ¨¡å‹å›å¤å†…å®¹æˆ– None
        """
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        response = self.call_llm(messages)
        
        if response and 'choices' in response and len(response['choices']) > 0:
            return response['choices'][0]['message']['content']
        
        return None

    def parse_text_to_blocks(self, text: str, section_context: str = "") -> List[Dict[str, Any]]:
        """
        è§£ææ–‡æœ¬å¹¶ç”Ÿæˆé€‚åˆæ·»åŠ åˆ°sectionä¸­çš„blockç»“æ„
        
        Args:
            text: éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹
            section_context: sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¸®åŠ©å¤§æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œè§£æ
            
        Returns:
            è§£æåçš„blockåˆ—è¡¨
        """
        safe_print("å¼€å§‹è§£ææ–‡æœ¬ä¸ºblocks")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
            error_msg = "LLMæœåŠ¡ä¸å¯ç”¨ï¼šæœªé…ç½®GLM_API_KEYæˆ–ä½¿ç”¨äº†å ä½ç¬¦å€¼ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„GLM APIå¯†é’¥ã€‚"
            safe_print(error_msg)
            # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™é»˜å›é€€ï¼Œè®©ç”¨æˆ·çŸ¥é“é—®é¢˜æ‰€åœ¨
            raise RuntimeError(error_msg)
        
        try:
            return self._extract_blocks_with_llm(text, section_context)
        except Exception as e:
            error_msg = f"LLMè§£æå¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼Œæˆ–ç¨åé‡è¯•ã€‚"
            safe_print(error_msg)
            # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™é»˜å›é€€ï¼Œè®©ç”¨æˆ·çŸ¥é“é—®é¢˜æ‰€åœ¨
            raise RuntimeError(error_msg)

    def parse_text_to_blocks_and_save(
        self,
        text: str,
        paper_id: str,
        section_id: str,
        section_context: str = "",
        user_id: str = "",
        after_block_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è§£ææ–‡æœ¬ä¸ºblockså¹¶ç›´æ¥ä¿å­˜åˆ°è®ºæ–‡ä¸­
        
        Args:
            text: éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹
            paper_id: è®ºæ–‡ID
            section_id: section ID
            section_context: sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            user_id: ç”¨æˆ·ID
            after_block_id: åœ¨æŒ‡å®šblockåæ’å…¥ï¼Œä¸ä¼ åˆ™åœ¨æœ«å°¾æ·»åŠ 
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        try:
            safe_print("å¼€å§‹è§£ææ–‡æœ¬å¹¶ä¿å­˜åˆ°è®ºæ–‡")
            safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            safe_print(f"è®ºæ–‡ID: {paper_id}")
            safe_print(f"Section ID: {section_id}")
            
            # é¦–å…ˆè§£ææ–‡æœ¬ä¸ºblocks
            parsed_blocks = self.parse_text_to_blocks(text, section_context)
            
            if not parsed_blocks:
                return {
                    "success": False,
                    "error": "æ–‡æœ¬è§£æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„blocks"
                }
            
            safe_print(f"æˆåŠŸè§£æç”Ÿæˆ {len(parsed_blocks)} ä¸ªblocks")
            
            # è·å–paperæœåŠ¡æ¥ä¿å­˜
            from ..services.paperService import get_paper_service
            paper_service = get_paper_service()
            
            # ç›´æ¥æ›´æ–°è®ºæ–‡ï¼Œä¸è°ƒç”¨å¯èƒ½ä¸å…¼å®¹çš„add_blocks_to_sectionæ–¹æ³•
            paper = paper_service.paper_model.find_by_id(paper_id)
            if paper:
                sections = paper.get("sections", [])
                target_section = None
                section_index = -1
                
                for i, section in enumerate(sections):
                    if section.get("id") == section_id:
                        target_section = section
                        section_index = i
                        break
                
                if target_section:
                    # ç¡®ä¿sectionæœ‰contentå­—æ®µ
                    if "content" not in target_section:
                        target_section["content"] = []
                    
                    # æ ¹æ®after_block_idç¡®å®šæ’å…¥ä½ç½®
                    current_blocks = target_section["content"]
                    insert_index = len(current_blocks)  # é»˜è®¤åœ¨æœ«å°¾
                    
                    if after_block_id:
                        for i, block in enumerate(current_blocks):
                            if block.get("id") == after_block_id:
                                insert_index = i + 1  # æ’å…¥åˆ°æŒ‡å®šblockåé¢
                                break
                    
                    # å®‰å…¨åœ°æ’å…¥æ–°blocks
                    safe_print(f"åœ¨ä½ç½® {insert_index} æ’å…¥ {len(parsed_blocks)} ä¸ªblocks")
                    new_blocks = current_blocks[:insert_index] + parsed_blocks + current_blocks[insert_index:]
                    target_section["content"] = new_blocks
                    sections[section_index] = target_section
                    
                    # æ›´æ–°è®ºæ–‡
                    update_data = {"sections": sections}
                    if paper_service.paper_model.update(paper_id, update_data):
                        updated_paper = paper_service.paper_model.find_by_id(paper_id)
                        return {
                            "success": True,
                            "message": f"æˆåŠŸå‘sectionæ·»åŠ äº†{len(parsed_blocks)}ä¸ªblocks",
                            "data": {
                                "paper": updated_paper,
                                "addedBlocks": parsed_blocks,
                                "sectionId": section_id,
                                "totalBlocks": len(parsed_blocks)
                            }
                        }
                    else:
                        return {
                            "success": False,
                            "error": "æ›´æ–°è®ºæ–‡å¤±è´¥"
                        }
                else:
                    return {
                        "success": False,
                        "error": f"æœªæ‰¾åˆ°æŒ‡å®šçš„section: {section_id}"
                    }
            else:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ°æŒ‡å®šçš„è®ºæ–‡: {paper_id}"
                }
            
        except Exception as e:
            safe_print(f"è§£æå¹¶ä¿å­˜å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"è§£æå¹¶ä¿å­˜å¤±è´¥: {str(e)}"
            }

    def _ensure_bilingual_inline(self,inline_items):
        """å°† InlineContent æ•°ç»„ä¸­ç¼ºå¤±è¯­è¨€çš„æ–‡æœ¬å¤åˆ¶ä¸ºåŒå†…å®¹ï¼Œç¡®ä¿ en/zh éƒ½æœ‰å€¼"""
        if not isinstance(inline_items, list):
            return []
        normalized = []
        for item in inline_items:
            if isinstance(item, dict):
                normalized.append(item)
            else:
                normalized.append({"type": "text", "text": str(item)})
        return normalized

    def _fill_missing_languages(self,block):
        """åœ¨ block çš„ content ä¸­è¡¥å…¨ en/zhï¼Œè‹¥ç¼ºå¤±åˆ™ä»¥å¦ä¸€è¯­è¨€å†…å®¹æˆ–ç©ºæ•°ç»„å›å¡«"""
        content = block.get("content")
        if not isinstance(content, dict):
            return block
        en = self._ensure_bilingual_inline(content.get("en"))
        zh = self._ensure_bilingual_inline(content.get("zh"))
        if not en and zh:
            en = [dict(item) for item in zh]
        if not zh and en:
            zh = [dict(item) for item in en]
        block["content"] = {"en": en, "zh": zh}
        return block

    def _extract_blocks_with_llm(self, text: str, section_context: str) -> List[Dict[str, Any]]:
        import json
        import re

        PARSER_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡å†…å®¹ç»“æ„åŒ–åŠ©æ‰‹ï¼Œä¸“æ³¨äºå°†æ–‡æœ¬å†…å®¹è§£æä¸ºæ ‡å‡†åŒ–çš„blockæ•°ç»„ã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
å°†è¾“å…¥çš„æ–‡æœ¬å†…å®¹è§£æä¸ºç¬¦åˆå­¦æœ¯è®ºæ–‡ç¼–è¾‘ç³»ç»Ÿçš„blockç»“æ„ï¼Œæ¯ä¸ªblockå¿…é¡»åŒ…å«ä¸­è‹±æ–‡å†…å®¹ã€‚

**ä¸¥æ ¼è¾“å‡ºè¦æ±‚ï¼š**
1. **å¿…é¡»è¾“å‡ºçº¯JSONæ•°ç»„æ ¼å¼** - ä»¥[å¼€å¤´ï¼Œ]ç»“å°¾ï¼Œä¸å…è®¸ä»»ä½•å…¶ä»–æ–‡å­—æˆ–æ ¼å¼
2. **æ¯ä¸ªblockçš„contentå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„**
3. **å³ä½¿åŸå§‹æ–‡æœ¬æ˜¯çº¯ä¸­æ–‡ï¼Œä¹Ÿè¦ç”Ÿæˆå¯¹åº”çš„è‹±æ–‡ç¿»è¯‘ï¼›åä¹‹äº¦ç„¶**
4. **ä¸å…è®¸ä»»ä½•å­—æ®µç¼ºå¤±æˆ–ä¸ºç©º**

**Blockç±»å‹åŠå­—æ®µè§„èŒƒï¼š**
- heading: æ ‡é¢˜ (éœ€è¦levelå­—æ®µ1-6)
- paragraph: æ®µè½ (content: {en: [...], zh: [...]})
- ordered-list: æœ‰åºåˆ—è¡¨ (itemsæ•°ç»„ï¼Œæ¯é¡¹åŒ…å«contentåŒè¯­è¨€)
- unordered-list: æ— åºåˆ—è¡¨ (itemsæ•°ç»„ï¼Œæ¯é¡¹åŒ…å«contentåŒè¯­è¨€)
- quote: å¼•ç”¨ (éœ€è¦authorå­—æ®µï¼ŒcontentåŒè¯­è¨€)
- math: æ•°å­¦å…¬å¼ (latexå­—æ®µä¿ç•™åŸå§‹å…¬å¼ï¼Œcontentä¸ºè§£é‡Šæ–‡å­—)
- code: ä»£ç  (languageå­—æ®µï¼Œcodeå­—æ®µä¿ç•™åŸå§‹ä»£ç )
- figure: å›¾ç‰‡ (src, alt, captionåŒè¯­è¨€)
- table: è¡¨æ ¼ (headers, rows, align)
- divider: åˆ†å‰²çº¿

**InlineContentç±»å‹ï¼š**
- text: æ™®é€šæ–‡æœ¬ï¼Œå¯åŒ…å«æ ·å¼
- link: é“¾æ¥
- inline-math: è¡Œå†…æ•°å­¦å…¬å¼ (å¿…é¡»ä½¿ç”¨latexå­—æ®µå­˜å‚¨å…¬å¼å†…å®¹ï¼Œä¸è¦ä½¿ç”¨contentå­—æ®µ)

**ç¿»è¯‘è¦æ±‚ï¼š**
- å¦‚æœåŸå§‹å†…å®¹æ˜¯ä¸­æ–‡ï¼Œzhæ•°ç»„æ”¾åŸæ–‡ï¼Œenæ•°ç»„æ”¾å‡†ç¡®è‹±æ–‡ç¿»è¯‘
- å¦‚æœåŸå§‹å†…å®¹æ˜¯è‹±æ–‡ï¼Œenæ•°ç»„æ”¾åŸæ–‡ï¼Œzhæ•°ç»„æ”¾å‡†ç¡®ä¸­æ–‡ç¿»è¯‘
- ä¿æŒå­¦æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§
- ä¿æŒæ•°å­¦å…¬å¼ã€ä»£ç ç­‰ç‰¹æ®Šå†…å®¹çš„æ ¼å¼

**é‡è¦æé†’ï¼š**
- æ¯ä¸ªblockçš„content.enå’Œcontent.zhéƒ½å¿…é¡»æ˜¯æ•°ç»„ï¼Œä¸èƒ½ä¸ºç©º
- å¦‚æœæ— æ³•ç¿»è¯‘ï¼Œå¤åˆ¶åŸæ–‡åˆ°ç›®æ ‡è¯­è¨€æ•°ç»„
- ä¸¥æ ¼éµå¾ªJSONæ ¼å¼ï¼Œä¸èƒ½æœ‰æ³¨é‡Šæˆ–é¢å¤–æ–‡å­—"""

        TRANSLATION_SYSTEM_PROMPT = """You are a professional academic translator specializing in scholarly content.

**Translation Requirements:**
- Preserve academic terminology and precision
- Maintain mathematical formulas, code, and technical terms exactly as they appear
- For Chinese to English: Use formal academic English appropriate for research papers
- For English to Chinese: Use standard academic Chinese terminology
- Keep references, and special formatting intact
- Output ONLY the translated text without any additional explanation or formatting markers"""

        chinese_char = re.compile(r"[\u4e00-\u9fff]")

        def _parse_markdown():
            safe_print("ğŸš€ å¼€å§‹ä½¿ç”¨LLMè§£ææ–‡æœ¬")
            section_title = section_context.splitlines()[0].strip() if section_context else ""
            context_info = f"å½“å‰sectionæ ‡é¢˜ï¼š{section_title}" if section_title else "æ— ç‰¹å®šsectionæ ‡é¢˜"
            
            # é™åˆ¶æ–‡æœ¬é•¿åº¦ä»¥é¿å…è¶…å‡ºtokené™åˆ¶
            truncated_text = text[:40000] if len(text) > 40000 else text
            safe_print(f"ğŸ” åŸå§‹æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            safe_print(f"ğŸ“ è§£ææ–‡æœ¬é•¿åº¦: {len(truncated_text)} å­—ç¬¦")
            if len(text) > 40000:
                safe_print("âš ï¸  æ–‡æœ¬è¢«æˆªæ–­ï¼Œå‰40,000å­—ç¬¦å°†è¢«è§£æ")
                safe_print(f"ğŸ“‹ æˆªæ–­çš„æ–‡æœ¬é¢„è§ˆ: {truncated_text[:200]}...")
            safe_print(f"ğŸ“Š æ–‡æœ¬å†…å®¹ç»Ÿè®¡: æ€»è¡Œæ•°={len(text.split(chr(10)))}")
            
            user_prompt = f"""è¯·å°†ä»¥ä¸‹æ–‡æœ¬å†…å®¹è§£æä¸ºæ ‡å‡†åŒ–çš„blockæ•°ç»„ã€‚

{context_info}

éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹ï¼š
{truncated_text}

**é‡è¦è¦æ±‚ï¼š**
1. æ¯ä¸ªblockçš„contentå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„
2. å¦‚æœåŸæ–‡æœ¬æ˜¯ä¸­æ–‡ï¼Œzhæ”¾åŸæ–‡ï¼Œenæ”¾è‹±æ–‡ç¿»è¯‘
3. å¦‚æœåŸæ–‡æœ¬æ˜¯è‹±æ–‡ï¼Œenæ”¾åŸæ–‡ï¼Œzhæ”¾ä¸­æ–‡ç¿»è¯‘
4. ä¿æŒå­¦æœ¯å†…å®¹çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
5. ä¸¥æ ¼è¾“å‡ºJSONæ•°ç»„æ ¼å¼ï¼Œä¸è¦å…¶ä»–ä»»ä½•æ–‡å­—"""

            messages = [
                {"role": "system", "content": PARSER_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ]
            
            safe_print("ğŸ“¤ å‘é€è§£æè¯·æ±‚åˆ°LLM...")
            response = self.call_llm(messages, temperature=0.2, max_tokens=100000)
            
            if not response or "choices" not in response:
                safe_print("âŒ LLMå“åº”æ ¼å¼é”™è¯¯")
                raise Exception("LLMå“åº”æ ¼å¼é”™è¯¯")
                
            content = response["choices"][0]["message"]["content"]
            safe_print(f"ğŸ’¬ LLMåŸå§‹å“åº”: {content[:500]}...")
            
            # æå–JSONå†…å®¹
            if "```json" in content:
                fence = "```json"
                start = content.find(fence) + len(fence)
                end = content.find("```", start)
                content = content[start:end].strip()
            elif "```" in content:
                fence = "```"
                start = content.find(fence) + len(fence)
                end = content.find("```", start)
                content = content[start:end].strip()
            
            # æ¸…ç†å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
            content = content.strip()
            if content.startswith('json'):
                content = content[4:].strip()
            
            safe_print(f"ğŸ”„ è§£æJSONå†…å®¹: {content[:200]}...")
            return json.loads(content)

        def _normalize_inline(items):
            """æ ‡å‡†åŒ–InlineContentæ•°ç»„"""
            normalized = []
            for item in items or []:
                if isinstance(item, dict):
                    normalized.append(item)
                elif isinstance(item, str):
                    normalized.append({"type": "text", "text": item})
            return normalized

        def _inline_plain_text(items):
            """æå–çº¯æ–‡æœ¬å†…å®¹ç”¨äºç¿»è¯‘"""
            fragments = []
            for item in items or []:
                if not isinstance(item, dict):
                    continue
                if item.get("type") == "text" and item.get("text"):
                    fragments.append(item["text"])
                elif item.get("type") == "link":
                    label = item.get("label") or item.get("text")
                    if label:
                        fragments.append(label)
            return " ".join(fragments).strip()

        def _rebuild_inline_from_text(text_value):
            """ä»çº¯æ–‡æœ¬é‡å»ºInlineContent"""
            text_value = (text_value or "").strip()
            return [{"type": "text", "text": text_value}] if text_value else []

        def _translate_content(source_items, target_lang):
            """ç¿»è¯‘InlineContentå†…å®¹"""
            plain_text = _inline_plain_text(source_items)
            if not plain_text:
                return []
            
            source_lang = "zh" if chinese_char.search(plain_text) else "en"
            if source_lang == target_lang:
                # åŒè¯­è¨€ï¼Œç›´æ¥è¿”å›
                return [dict(item) for item in source_items]
            
            messages = [
                {"role": "system", "content": TRANSLATION_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": f"Source language: {source_lang}\nTarget language: {target_lang}\n\nSource text:\n{plain_text}\n\nReturn only the translated text.",
                },
            ]
            
            try:
                safe_print(f"ğŸ”„ ç¿»è¯‘å†…å®¹ ({source_lang} -> {target_lang}): {plain_text[:50]}...")
                resp = self.call_llm(messages, temperature=0.1, max_tokens=100000)
                
                if resp and "choices" in resp:
                    translated = resp["choices"][0]["message"]["content"].strip()
                    safe_print(f"âœ… ç¿»è¯‘å®Œæˆ: {translated[:50]}...")
                    return _rebuild_inline_from_text(translated)
                else:
                    safe_print("âŒ ç¿»è¯‘å“åº”æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨åŸæ–‡")
                    return [dict(item) for item in source_items]
            except Exception as exc:
                safe_print(f"âŒ ç¿»è¯‘å¤±è´¥ ({source_lang}->{target_lang}): {exc}")
                return [dict(item) for item in source_items]

        def _fix_inline_math_in_paragraph(block):
            """ä¿®å¤paragraphä¸­inline-mathçš„å­—æ®µé—®é¢˜ï¼Œå°†contentå­—æ®µæ”¹ä¸ºlatexå­—æ®µ"""
            if block.get("type") != "paragraph":
                return block
                
            content = block.get("content", {})
            if not isinstance(content, dict):
                return block
                
            # ä¿®å¤è‹±æ–‡å†…å®¹
            en_content = content.get("en", [])
            if isinstance(en_content, list):
                for item in en_content:
                    if isinstance(item, dict) and item.get("type") == "inline-math":
                        if "content" in item and "latex" not in item:
                            item["latex"] = item.pop("content")
                            safe_print(f"ğŸ”§ ä¿®å¤inline-math: content -> latex")
                            
            # ä¿®å¤ä¸­æ–‡å†…å®¹
            zh_content = content.get("zh", [])
            if isinstance(zh_content, list):
                for item in zh_content:
                    if isinstance(item, dict) and item.get("type") == "inline-math":
                        if "content" in item and "latex" not in item:
                            item["latex"] = item.pop("content")
                            safe_print(f"ğŸ”§ ä¿®å¤inline-math: content -> latex")
                            
            return block

        def _ensure_bilingual_content(block):
            """ç¡®ä¿blockçš„contentåŒ…å«åŒè¯­è¨€å†…å®¹"""
            content = block.get("content")
            if not isinstance(content, dict):
                return block

            # è·å–ç°æœ‰å†…å®¹
            en_items = _normalize_inline(content.get("en", []))
            zh_items = _normalize_inline(content.get("zh", []))

            # å¦‚æœç¼ºå°‘æŸç§è¯­è¨€ï¼Œè¿›è¡Œç¿»è¯‘
            if not en_items and zh_items:
                en_items = _translate_content(zh_items, "en")
            if not zh_items and en_items:
                zh_items = _translate_content(en_items, "zh")

            # ç¡®ä¿ä¸¤ç§è¯­è¨€éƒ½æœ‰å†…å®¹
            if not en_items:
                en_items = [dict(item) for item in zh_items] if zh_items else []
            if not zh_items:
                zh_items = [dict(item) for item in en_items] if en_items else []

            block["content"] = {"en": en_items, "zh": zh_items}
            return block

        try:
            safe_print("ğŸ”„ å¼€å§‹LLMè§£ææµç¨‹")
            blocks = _parse_markdown()
            
        except Exception as exc:
            safe_print(f"âŒ LLMè§£æå¤±è´¥: {exc}")
            safe_print("ğŸ”™ å›é€€åˆ°ç®€å•è§£æ")
            return self._simple_text_to_blocks(text)

        if not isinstance(blocks, list):
            safe_print("âŒ LLMè¿”å›çš„ä¸æ˜¯blockåˆ—è¡¨")
            return self._simple_text_to_blocks(text)

        safe_print(f"âœ… éªŒè¯å’Œæ ‡å‡†åŒ–{len(blocks)}ä¸ªblocks...")
        from ..utils.common import generate_id, get_current_time

        validated_blocks = []
        for i, block in enumerate(blocks):
            try:
                if not isinstance(block, dict) or "type" not in block:
                    safe_print(f"â­ï¸  è·³è¿‡æ— æ•ˆblock: {block}")
                    continue

                # ä¿®å¤inline-mathçš„å­—æ®µé—®é¢˜
                if block.get("type") == "paragraph":
                    block = _fix_inline_math_in_paragraph(block)
                
                # ç¡®ä¿contentæ˜¯å­—å…¸
                if "content" not in block or not isinstance(block["content"], dict):
                    block["content"] = {"en": [], "zh": []}
                
                # ç¡®ä¿åŒè¯­è¨€å†…å®¹
                block = _ensure_bilingual_content(block)
                
                # æ·»åŠ å¿…è¦å­—æ®µ
                block["id"] = generate_id()
                block["createdAt"] = get_current_time().isoformat()  # è½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
                
                validated_blocks.append(block)
                safe_print(f"âœ… éªŒè¯block {i+1}: {block.get('type')}")
                
            except Exception as exc:
                safe_print(f"âŒ éªŒè¯blockå¤±è´¥: {exc}")
                continue

        safe_print(f"ğŸ‰ å®ŒæˆéªŒè¯ï¼Œç”Ÿæˆ{len(validated_blocks)}ä¸ªæœ‰æ•ˆblocks")
        return validated_blocks

    

    def _simple_text_to_blocks(self, text: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è§£ææ–‡æœ¬ä¸ºblocksçš„æ–¹æ³•"""
        from ..utils.common import generate_id, get_current_time
        import json
        
        safe_print("ğŸ”„ å¼€å§‹LLMæ–‡æœ¬è§£æ")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # åˆå§‹åŒ–LLMå·¥å…·
        llm_utils = LLMUtils()
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æ–‡æ¡£ç»“æ„åŒ–è§£æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†è¾“å…¥çš„æ–‡æœ¬è§£æä¸ºç»“æ„åŒ–çš„JSONæ ¼å¼çš„blocksæ•°ç»„ã€‚

    æ ¸å¿ƒåŸåˆ™ï¼š
    1. ç»å¯¹ä¸è¦ä¿®æ”¹åŸæ–‡å†…å®¹ï¼Œä¿æŒæ‰€æœ‰æ–‡æœ¬çš„åŸæ ·ï¼ŒåŒ…æ‹¬æ ‡ç‚¹ç¬¦å·ã€ç©ºæ ¼ã€æ¢è¡Œ
    2. å‡†ç¡®è¯†åˆ«è¯­è¨€ï¼Œè‡ªåŠ¨æ£€æµ‹ä¸­æ–‡(zh)æˆ–è‹±æ–‡(en)ï¼Œå¯¹äºæ¯ä¸ªæ–‡æœ¬å†…å®¹ï¼Œå°†å…¶æ”¾åœ¨å¯¹åº”è¯­è¨€å­—æ®µä¸­
    3. æ™ºèƒ½è¯†åˆ«ç»“æ„ï¼Œæ­£ç¡®è¯†åˆ«æ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ã€å…¬å¼ã€ä»£ç å—ç­‰ä¸åŒç±»å‹
    4. å¤„ç†è¡Œå†…å…ƒç´ ï¼Œè¯†åˆ«é“¾æ¥ã€è¡Œå†…å…¬å¼
    5. æ•°å­¦å…¬å¼æ ¼å¼ï¼šè¡Œå†…å…¬å¼è¯†åˆ«$...$åè½¬æ¢å­˜å‚¨æ ¼å¼ï¼Œè¡Œé—´å…¬å¼è¯†åˆ«$$...$$æˆ–åæ–œæ æ–¹æ‹¬å·åä½¿ç”¨åæ–œæ æ–¹æ‹¬å·æ ¼å¼
    6. è·³è¿‡å‚è€ƒæ–‡çŒ®ï¼Œå¦‚æœè¯†åˆ«åˆ°Referencesã€å‚è€ƒæ–‡çŒ®ç­‰ç« èŠ‚ï¼Œå¯ä»¥å¿½ç•¥å…¶å†…å®¹
    7. ä¸€èˆ¬æ¥è¯´è¾“å…¥éƒ½æ˜¯è‹±æ–‡ï¼Œå¦‚æœè¾“å…¥çš„è‹±æ–‡ï¼Œè¯·ä½ è‡ªåŠ¨è¡¥å…¨ç»“æ„ä¸­zhçš„éƒ¨åˆ†

    Blockç±»å‹å®šä¹‰ï¼š

    1. heading æ ‡é¢˜
    å¿…éœ€å­—æ®µï¼štypeä¸ºheadingï¼ŒcontentåŒ…å«enæˆ–zhæ•°ç»„
    è¯†åˆ«æ ‡è®°ï¼šä»…ä»…è¯†åˆ«å“ªäº›ç®€çŸ­çš„æ ‡é¢˜ï¼Œä¾‹å¦‚#å¼€å¤´çš„æ ‡é¢˜

    2. paragraph æ®µè½
    è¯†åˆ«æ ‡è®°ï¼šæ™®é€šæ–‡æœ¬æ®µè½
    å¿…éœ€å­—æ®µï¼štypeä¸ºparagraphï¼ŒcontentåŒ…å«enæˆ–zhæ•°ç»„ï¼Œå…·ä½“è§inlineContentæè¿°

    3. math æ•°å­¦å…¬å¼å—
    è¯†åˆ«æ ‡è®°ï¼šç‹¬ç«‹çš„åŒç¾å…ƒç¬¦å·æˆ–åæ–œæ æ–¹æ‹¬å·
    å¤„ç†ï¼šéœ€è¦ç§»é™¤å…¶ç¼–å·
    å¿…éœ€å­—æ®µï¼štypeä¸ºmathï¼Œlatexä¸ºå…¬å¼å†…å®¹ï¼ˆä½¿ç”¨åæ–œæ æ–¹æ‹¬å·æ ¼å¼åŒ…è£¹ï¼‰

    4. code ä»£ç å—
    è¯†åˆ«æ ‡è®°ï¼šä¸‰ä¸ªåå¼•å·æˆ–ç¼©è¿›çš„ä»£ç 
    å¿…éœ€å­—æ®µï¼štypeä¸ºcodeï¼Œcodeä¸ºä»£ç å†…å®¹

    5. ordered-list æœ‰åºåˆ—è¡¨
    è¯†åˆ«æ ‡è®°ï¼šæ•°å­—åŠ ç‚¹å¼€å¤´å¦‚1. 2. 3.
    å¿…éœ€å­—æ®µï¼štypeä¸ºordered-listï¼Œitemsæ•°ç»„ï¼Œæ¯é¡¹åŒ…å«contentå¯¹è±¡

    6. unordered-list æ— åºåˆ—è¡¨
    è¯†åˆ«æ ‡è®°ï¼šå‡å·ã€æ˜Ÿå·ã€åŠ å·å¼€å¤´
    å¿…éœ€å­—æ®µï¼štypeä¸ºunordered-listï¼Œitemsæ•°ç»„ï¼Œæ¯é¡¹åŒ…å«contentå¯¹è±¡

    7. quote å¼•ç”¨å—
    è¯†åˆ«æ ‡è®°ï¼šå¤§äºå·å¼€å¤´
    å¿…éœ€å­—æ®µï¼štypeä¸ºquoteï¼ŒcontentåŒ…å«enæˆ–zhæ•°ç»„

    8. table è¡¨æ ¼
    è¯†åˆ«æ ‡è®°ï¼šmarkdownè¡¨æ ¼æ ¼å¼
    å¿…éœ€å­—æ®µï¼štypeä¸ºtableï¼Œrowsä¸ºäºŒç»´æ•°ç»„

    9. divider åˆ†éš”çº¿
    è¯†åˆ«æ ‡è®°ï¼šä¸‰ä¸ªå‡å·æˆ–ä¸‰ä¸ªæ˜Ÿå·
    å¿…éœ€å­—æ®µï¼štypeä¸ºdivider

    10. figure å›¾ç‰‡
    è¯†åˆ«æ ‡è®°ï¼šæ„Ÿå¹å·åŠ æ–¹æ‹¬å·åŠ åœ†æ‹¬å·
    å¿…éœ€å­—æ®µï¼štypeä¸ºfigureï¼Œsrcä¸ºå›¾ç‰‡URL

    InlineContentç±»å‹å®šä¹‰ï¼š

    1. text æ™®é€šæ–‡æœ¬
    typeä¸ºtextï¼Œcontentä¸ºæ–‡æœ¬å†…å®¹
    å¯é€‰styleå¯¹è±¡åŒ…å«boldç²—ä½“ã€italicæ–œä½“ã€codeä»£ç ã€underlineä¸‹åˆ’çº¿ã€strikethroughåˆ é™¤çº¿

    2. link é“¾æ¥
    typeä¸ºlinkï¼Œurlä¸ºé“¾æ¥åœ°å€ï¼Œchildrenä¸ºå­å…ƒç´ æ•°ç»„
    å¯é€‰titleæ ‡é¢˜

    3. inline-math è¡Œå†…å…¬å¼
    typeä¸ºinline-mathï¼Œlatexä¸ºå…¬å¼å†…å®¹ï¼ˆä¸åŒ…å«ç¾å…ƒç¬¦å·ï¼Œå¿…é¡»ä½¿ç”¨latexå­—æ®µä¸è¦ä½¿ç”¨contentå­—æ®µï¼‰ï¼Œæ³¨æ„è¯†åˆ«ï¼Œè¡Œå†…å…¬å¼ä¸€èˆ¬ä¸æ¢è¡Œï¼Œå¹¶ä¸”å·¦å³åªæœ‰ä¸€ä¸ª$ä»˜è±ª

    è¿”å›æ ¼å¼è¦æ±‚ï¼š

    å¿…é¡»è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«blocksæ•°ç»„å­—æ®µã€‚

    ç¤ºä¾‹ç»“æ„ï¼š
    {
    "blocks": [
        {
        "type": "heading",
        "level": 1,
        "content": {
            "en": [{"type": "text", "content": "Introduction"}]
        }
        },
        {
        "type": "paragraph",
        "content": {
            "en": [
            {"type": "text", "content": "This is "},
            {"type": "text", "content": "bold text", "style": {"bold": true}},
            {"type": "text", "content": " with "},
            {"type": "inline-math", "latex": "x^2"},
            {"type": "text", "content": "."}
            ]
        }
        },
        {
        "type": "math",
        "latex": "E = mc^2"
        },
        {
        "type": "unordered-list",
        "items": [
            {
            "content": {
                "en": [{"type": "text", "content": "First item"}]
                "zh":[{"type":"text","content":"ç¬¬ä¸€ä¸ªå…ƒç´ "}]
            }
            },
            {
            "content": {
                "en": [{"type": "text", "content": "Second item"}]
            }
            }
        ]
        }
    ]
    }

    ç‰¹æ®Šå¤„ç†è§„åˆ™ï¼š

    1. æ•°å­¦å…¬å¼è¯†åˆ«
    è¡Œå†…ï¼šå•ç¾å…ƒç¬¦å·åŒ…è£¹è½¬ä¸ºinline-mathç±»å‹ï¼Œå¿…é¡»ä½¿ç”¨latexå­—æ®µå­˜å‚¨å…¬å¼å†…å®¹ï¼Œä¸è¦ä½¿ç”¨contentå­—æ®µ
    è¡Œé—´ï¼šåŒç¾å…ƒç¬¦å·æˆ–åæ–œæ æ–¹æ‹¬å·è½¬ä¸ºmath blockç±»å‹

    2. æ–‡æœ¬æ ·å¼è¯†åˆ«
    åŒæ˜Ÿå·æˆ–åŒä¸‹åˆ’çº¿ä¸ºç²—ä½“

    3. åˆ—è¡¨å¤„ç†
    ä¸æ”¯æŒåµŒå¥—åˆ—è¡¨ï¼Œå°†åµŒå¥—é¡¹å±•å¹³å¤„ç†

    4. æ··åˆè¯­è¨€å¤„ç†
    å¦‚æœæ®µè½åŒ…å«ä¸­è‹±æ–‡æ··åˆï¼Œæ£€æµ‹ä¸»è¦è¯­è¨€å¹¶æ”¾å…¥å¯¹åº”å­—æ®µ

    5. ç©ºç™½ä¿ç•™
    æ®µè½é—´ç©ºè¡Œä½œä¸ºæ®µè½åˆ†éš”ï¼Œä¸éœ€åˆ›å»ºç©ºç™½block

    6. é”™è¯¯å¤„ç†
    æ— æ³•è¯†åˆ«çš„ç»“æ„ä¼˜å…ˆè§£æä¸ºparagraphç±»å‹

    ç°åœ¨è¯·å°†è¾“å…¥çš„æ–‡æœ¬è§£æä¸ºblocksæ•°ç»„ã€‚è®°ä½ï¼šä¸è¦ä¿®æ”¹ä»»ä½•åŸæ–‡å†…å®¹ï¼Œåªéœ€è¯†åˆ«ç»“æ„å¹¶è½¬æ¢ä¸ºJSONæ ¼å¼ã€‚"""

        try:
            # å‡†å¤‡æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": f"è¯·è§£æä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{text}"
                }
            ]
            
            # è°ƒç”¨LLM
            safe_print("ğŸ“¡ æ­£åœ¨è°ƒç”¨GLM API...")
            result = llm_utils.call_llm(
                messages=messages,
                model=LLMModel.GLM_4_6,
                temperature=0.1,
                max_tokens=100000
            )
            
            if not result:
                safe_print("âŒ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return self._fallback_simple_parse(text)
            
            # æå–å“åº”å†…å®¹
            if 'choices' not in result or not result['choices']:
                safe_print("âŒ LLMå“åº”æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return self._fallback_simple_parse(text)
            
            content = result['choices'][0]['message']['content']
            safe_print(f"ğŸ“¥ æ”¶åˆ°å“åº”ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
            safe_print(f"å“åº”å†…å®¹é¢„è§ˆ: {content[:500]}...")
            
            # è§£æJSON
            try:
                # å°è¯•ç›´æ¥è§£æ
                parsed_result = json.loads(content)
            except json.JSONDecodeError:
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                safe_print("âš ï¸ ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†")
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    parsed_result = json.loads(json_match.group())
                else:
                    safe_print("âŒ æ— æ³•æå–JSONï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                    return self._fallback_simple_parse(text)
            
            # è·å–blocksæ•°ç»„
            blocks = parsed_result.get("blocks", [])
            
            if not blocks:
                safe_print("âš ï¸ æœªæ‰¾åˆ°blocksæ•°ç»„ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return self._fallback_simple_parse(text)
            
            # ä¸ºæ¯ä¸ªblockæ·»åŠ idå’ŒcreatedAt
            for block in blocks:
                if 'id' not in block:
                    block['id'] = generate_id()
                if 'createdAt' not in block:
                    block['createdAt'] = get_current_time().isoformat()  # è½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
            
            safe_print(f"ğŸ‰ LLMè§£æå®Œæˆï¼Œç”Ÿæˆ {len(blocks)} ä¸ªblocks")
            
            # æ‰“å°å‰å‡ ä¸ªblockçš„ç±»å‹
            if blocks:
                safe_print("ğŸ“‹ å‰5ä¸ªblocksç±»å‹ï¼š")
                for i, block in enumerate(blocks[:5]):
                    safe_print(f"  {i+1}. {block.get('type', 'unknown')}")
            
            return blocks
            
        except Exception as e:
            safe_print(f"âŒ LLMè§£æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            safe_print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return self._fallback_simple_parse(text)


    def _fallback_simple_parse(self, text: str) -> List[Dict[str, Any]]:
        """é™çº§æ–¹æ¡ˆï¼šç®€å•è§£æ"""
        from ..utils.common import generate_id, get_current_time
        import re
        
        safe_print("âš ï¸ ä½¿ç”¨é™çº§è§£ææ–¹æ¡ˆ")
        
        blocks = []
        chinese_char = re.compile(r"[\u4e00-\u9fff]")
        
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        safe_print(f"ğŸ“Š è¯†åˆ«åˆ° {len(paragraphs)} ä¸ªæ®µè½")
        
        for i, paragraph in enumerate(paragraphs):
            # æ£€æµ‹è¯­è¨€
            is_chinese = bool(chinese_char.search(paragraph))
            lang_key = "zh" if is_chinese else "en"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜
            if paragraph.startswith('#'):
                level = len(paragraph) - len(paragraph.lstrip('#'))
                level = min(level, 6)
                content_text = paragraph.lstrip('#').strip()
                
                block = {
                    'id': generate_id(),
                    'type': 'heading',
                    'level': level,
                    'content': {
                        lang_key: [{"type": "text", "content": content_text}]
                    },
                    'createdAt': get_current_time().isoformat()  # è½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
                }
            else:
                # åˆ›å»ºåŸºæœ¬çš„paragraph block
                block = {
                    'id': generate_id(),
                    'type': 'paragraph',
                    'content': {
                        lang_key: [{"type": "text", "content": paragraph}]
                    },
                    'createdAt': get_current_time().isoformat()  # è½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
                }
            
            blocks.append(block)
            safe_print(f"ğŸ“ ç”Ÿæˆblock {i+1}: {block['type']}")
        
        safe_print(f"âœ… é™çº§è§£æå®Œæˆï¼Œç”Ÿæˆ {len(blocks)} ä¸ªblocks")
        return blocks

# å…¨å±€å®ä¾‹
_llm_utils: Optional[LLMUtils] = None

def get_llm_utils() -> LLMUtils:
    """è·å– LLMUtils å…¨å±€å®ä¾‹"""
    global _llm_utils
    if _llm_utils is None:
        _llm_utils = LLMUtils()
    return _llm_utils