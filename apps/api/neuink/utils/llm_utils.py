"""
å¤§æ¨¡å‹å·¥å…·ç±»
æ”¯æŒå¤šç§å¤§æ¨¡å‹è°ƒç”¨ï¼Œç›®å‰é›†æˆ GLM-4.6 æ¨¡å‹
"""

import os
import sys
import json
import requests
import locale
from typing import Dict, Any, Optional, List
from enum import Enum

import logging
import threading

# é…ç½®æ—¥å¿—ç³»ç»Ÿ - ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„é…ç½®
def setup_logger():
    """è®¾ç½®çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å™¨"""
    logger = logging.getLogger(__name__)
    
    # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
    if logger.handlers:
        return logger
    
    logger.setLevel(logging.INFO)
    
    # åˆ›å»ºæ ¼å¼å™¨
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    
    # æ–‡ä»¶å¤„ç†å™¨ - ç¡®ä¿çº¿ç¨‹å®‰å…¨
    file_handler = logging.FileHandler('neuink_llm.log', encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å°å¤„ç†å™¨ - ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„å¤„ç†æ–¹å¼
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

# åˆå§‹åŒ–æ—¥å¿—å™¨
logger = setup_logger()

# åˆ›å»ºçº¿ç¨‹é”ä»¥ç¡®ä¿æ—¥å¿—è¾“å‡ºçš„çº¿ç¨‹å®‰å…¨
_log_lock = threading.Lock()

# å®‰å…¨çš„æ—¥å¿—æ‰“å°å‡½æ•°
def safe_print(*args, **kwargs):
    """å®‰å…¨çš„æ‰“å°å‡½æ•°ï¼Œé¿å…ç¼–ç é”™è¯¯ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶å’Œæ§åˆ¶å°"""
    global _log_lock
    # ç¡®ä¿_log_lockå·²åˆå§‹åŒ–
    if _log_lock is None:
        _log_lock = threading.Lock()
    
    with _log_lock:  # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿çº¿ç¨‹å®‰å…¨
        try:
            # æ„å»ºæ¶ˆæ¯å­—ç¬¦ä¸²
            message = ' '.join(str(arg) for arg in args)
            
            # è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆUTF-8ç¼–ç ï¼‰
            logger.info(message)
            
            # å°è¯•è¾“å‡ºåˆ°æ§åˆ¶å°
            try:
                print(message, **kwargs)
            except UnicodeEncodeError:
                # Windowsæ§åˆ¶å°ç¼–ç é”™è¯¯å¤„ç†
                try:
                    # å°è¯•ä½¿ç”¨Windowsæ§åˆ¶å°å…¼å®¹çš„ç¼–ç 
                    print(message.encode('gbk', errors='replace').decode('gbk'), **kwargs)
                except:
                    # æœ€åçš„å…œåº•æ–¹æ¡ˆï¼šç§»é™¤éASCIIå­—ç¬¦
                    safe_message = ''.join(char if ord(char) < 128 else '?' for char in message)
                    print(safe_message, **kwargs)
                    
        except Exception as e:
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè‡³å°‘è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
            try:
                logger.error(f"safe_print failed: {e}")
            except:
                pass  # é¿å…é€’å½’é”™è¯¯

class LLMModel(Enum):
    """æ”¯æŒçš„å¤§æ¨¡å‹æšä¸¾"""
    GLM_4_6 = "glm-4.6"
    GLM_4_5 = "glm-4.5"
    GLM_4_PLUS = "glm-4-plus"
    # æœªæ¥å¯ä»¥æ‰©å±•å…¶ä»–æ¨¡å‹
    # GPT_4 = "gpt-4"
    # CLAUDE_3 = "claude-3"

class LLMUtils:
    """å¤§æ¨¡å‹å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®"""
        self.glm_api_key = os.getenv('GLM_API_KEY')
        self.glm_base_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        safe_print(f"GLM API Key çŠ¶æ€: {'[å·²é…ç½®]' if self.glm_api_key and self.glm_api_key != 'your_glm_api_key_here' else '[æœªé…ç½®æˆ–ä¸ºå ä½ç¬¦]'}")
        safe_print(f"[APIç«¯ç‚¹]: {self.glm_base_url}")
        
    def call_llm(
        self,
        messages: List[Dict[str, str]],
        model: LLMModel = LLMModel.GLM_4_6,
        temperature: float = 0.1,
        max_tokens: int = 100000,
        stream: bool = True,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨å¤§æ¨¡å‹æ¥å£
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": "..."}]
            model: ä½¿ç”¨çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–æ¨¡å‹ç‰¹å®šå‚æ•°
            
        Returns:
            æ¨¡å‹å“åº”ç»“æœæˆ– Noneï¼ˆå¦‚æœå‡ºé”™ï¼‰
        """
        if model == LLMModel.GLM_4_6:
            return self._call_glm(messages, temperature, max_tokens, stream, **kwargs)
        elif model == LLMModel.GLM_4_5:
            return self._call_glm(messages, temperature, max_tokens, stream, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}")
    
    def call_llm_stream(
        self,
        messages: List[Dict[str, str]],
        model: LLMModel = LLMModel.GLM_4_6,
        temperature: float = 0.1,
        max_tokens: int = 100000,
        **kwargs
    ):
        """
        è°ƒç”¨å¤§æ¨¡å‹æ¥å£ï¼ˆæµå¼è¾“å‡ºï¼‰
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": "..."}]
            model: ä½¿ç”¨çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            **kwargs: å…¶ä»–æ¨¡å‹ç‰¹å®šå‚æ•°
            
        Yields:
            æµå¼å“åº”çš„æ¯ä¸ªchunk
        """
        if model == LLMModel.GLM_4_6:
            yield from self._call_glm_stream(messages, temperature, max_tokens, **kwargs)
        elif model == LLMModel.GLM_4_5:
            yield from self._call_glm_stream(messages, temperature, max_tokens, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}")
    
    def _call_glm(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        stream: bool,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ GLM æ¨¡å‹
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            GLM å“åº”ç»“æœæˆ– None
        """
        safe_print("å¼€å§‹è°ƒç”¨GLM API")
        safe_print(f"è¯·æ±‚æ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        if not self.glm_api_key:
            safe_print("é”™è¯¯ï¼šæœªè®¾ç½® GLM_API_KEY ç¯å¢ƒå˜é‡")
            return None
            
        # ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹åç§°
        payload = {
            "model": LLMModel.GLM_4_6.value,  # ä¿®å¤ï¼šä½¿ç”¨ glm-4.6
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream,
            **kwargs
        }
        
        safe_print(f"æ¨¡å‹: {payload['model']}")
        safe_print(f"æ¸©åº¦: {payload['temperature']}")
        safe_print(f"æœ€å¤§Tokenæ•°: {payload['max_tokens']}")
        safe_print("æ¶ˆæ¯å†…å®¹é¢„è§ˆ:")
        for i, msg in enumerate(messages):
            safe_print(f"  {i+1}. [{msg['role']}] {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}")
        
        # æ£€æŸ¥APIå¯†é’¥é•¿åº¦å’Œæ ¼å¼
        if len(self.glm_api_key) < 20:
            safe_print(f"è­¦å‘Šï¼šAPIå¯†é’¥é•¿åº¦å¼‚å¸¸ ({len(self.glm_api_key)} å­—ç¬¦)")
        
        headers = {
            "Authorization": f"Bearer {self.glm_api_key}",  # æ˜¾ç¤ºå®Œæ•´å¯†é’¥ä¾¿äºè°ƒè¯•
            "Content-Type": "application/json"
        }
        
        try:
            safe_print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°GLM API...")
            safe_print(f"APIç«¯ç‚¹: {self.glm_base_url}")
            
            # è¯¦ç»†è®°å½•è¯·æ±‚ä½“
            safe_print("è¯·æ±‚ä½“é¢„è§ˆ:")
            safe_print(f"  model: {payload['model']}")
            safe_print(f"  temperature: {payload['temperature']}")
            safe_print(f"  max_tokens: {payload['max_tokens']}")
            safe_print(f"  stream: {payload['stream']}")
            
            response = requests.post(
                self.glm_base_url,
                json=payload,
                headers=headers,
                timeout=300  # å¢åŠ åˆ°300ç§’è¶…æ—¶
            )
            
            safe_print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            safe_print(f"å“åº”å¤´: {dict(response.headers)}")
            
            # å¦‚æœæ˜¯401é”™è¯¯ï¼Œæ˜¾ç¤ºå“åº”å†…å®¹
            if response.status_code == 401:
                try:
                    error_response = response.json()
                    safe_print(f"401é”™è¯¯è¯¦æƒ…: {error_response}")
                except:
                    safe_print(f"401é”™è¯¯å“åº”å†…å®¹: {response.text[:500]}")
            
            response.raise_for_status()
            
            result = response.json()
            safe_print("GLM APIè°ƒç”¨æˆåŠŸ")
            
            if 'choices' in result:
                safe_print(f"è¿”å›é€‰æ‹©æ•°é‡: {len(result['choices'])}")
                if result['choices']:
                    content = result['choices'][0]['message']['content']
                    safe_print(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                    safe_print(f"å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}{'...' if len(content) > 200 else ''}")
            
            return result
            
        except requests.exceptions.RequestException as e:
            safe_print(f"GLM API è°ƒç”¨å¤±è´¥: {e}")
            if hasattr(e, 'response'):
                safe_print(f"è¯·æ±‚è¯¦æƒ…: çŠ¶æ€ç  {e.response.status_code}")
                try:
                    error_content = e.response.json()
                    safe_print(f"é”™è¯¯è¯¦æƒ…: {error_content}")
                except:
                    safe_print(f"é”™è¯¯å“åº”: {e.response.text[:500]}")
            else:
                safe_print(f"è¯·æ±‚è¯¦æƒ…: æ— å“åº”å¯¹è±¡")
            return None
        except json.JSONDecodeError as e:
            safe_print(f"GLM API å“åº”è§£æå¤±è´¥: {e}")
            return None
    
    def _call_glm_stream(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        **kwargs
    ):
        """
        è°ƒç”¨ GLM æ¨¡å‹ï¼ˆæµå¼è¾“å‡ºï¼‰
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            æµå¼å“åº”çš„æ¯ä¸ªchunkï¼ŒåŒ…å«GLMçš„åŸå§‹æ•°æ®
        """
        safe_print("å¼€å§‹è°ƒç”¨GLM API (æµå¼)")
        safe_print(f"è¯·æ±‚æ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        if not self.glm_api_key:
            safe_print("é”™è¯¯ï¼šæœªè®¾ç½® GLM_API_KEY ç¯å¢ƒå˜é‡")
            yield {"error": "æœªè®¾ç½® GLM_API_KEY ç¯å¢ƒå˜é‡"}
            return
            
        # ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹åç§°
        payload = {
            "model": LLMModel.GLM_4_6.value,  # ä¿®å¤ï¼šä½¿ç”¨ glm-4.6
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": True,  # å¯ç”¨æµå¼è¾“å‡º
            **kwargs
        }
        
        safe_print(f"æ¨¡å‹: {payload['model']}")
        safe_print(f"æ¸©åº¦: {payload['temperature']}")
        safe_print(f"æœ€å¤§Tokenæ•°: {payload['max_tokens']}")
        safe_print("æ¶ˆæ¯å†…å®¹é¢„è§ˆ:")
        for i, msg in enumerate(messages):
            safe_print(f"  {i+1}. [{msg['role']}] {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}")
        
        headers = {
            "Authorization": f"Bearer {self.glm_api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            safe_print("æ­£åœ¨å‘é€æµå¼è¯·æ±‚åˆ°GLM API...")
            safe_print(f"APIç«¯ç‚¹: {self.glm_base_url}")
            
            response = requests.post(
                self.glm_base_url,
                json=payload,
                headers=headers,
                stream=True,  # å¯ç”¨æµå¼å“åº”
                timeout=300  # å¢åŠ åˆ°300ç§’è¶…æ—¶
            )
            
            safe_print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 401:
                try:
                    error_response = response.json()
                    safe_print(f"401é”™è¯¯è¯¦æƒ…: {error_response}")
                except:
                    safe_print(f"401é”™è¯¯å“åº”å†…å®¹: {response.text[:500]}")
            
            response.raise_for_status()
            
            # å¤„ç†æµå¼å“åº”ï¼Œç›´æ¥ä¼ é€’GLMçš„åŸå§‹æ•°æ®
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data: '):
                        data_str = line[6:]  # å»æ‰ 'data: ' å‰ç¼€
                        
                        if data_str.strip() == '[DONE]':
                            yield {"type": "done", "data": "[DONE]"}
                            break
                            
                        try:
                            # ç›´æ¥ä¼ é€’GLMçš„åŸå§‹JSONæ•°æ®
                            data = json.loads(data_str)
                            if 'choices' in data and len(data['choices']) > 0:
                                delta = data['choices'][0].get('delta', {})
                                if 'content' in delta:
                                    # è¿”å›GLMçš„åŸå§‹æ•°æ®ï¼ŒåŒ…å«tokenä½¿ç”¨ä¿¡æ¯ç­‰
                                    yield {
                                        "type": "glm_stream",
                                        "raw_data": data,  # GLMçš„åŸå§‹æ•°æ®
                                        "content": delta['content'],
                                        "model": data.get("model", payload["model"]),
                                        "usage": data.get("usage", {})  # tokenä½¿ç”¨ä¿¡æ¯
                                    }
                        except json.JSONDecodeError:
                            # å¿½ç•¥æ— æ³•è§£æçš„è¡Œ
                            continue
                            
        except requests.exceptions.RequestException as e:
            safe_print(f"GLM API æµå¼è°ƒç”¨å¤±è´¥: {e}")
            yield {"error": f"APIè°ƒç”¨å¤±è´¥: {e}"}
        except Exception as e:
            safe_print(f"GLM API æµå¼è°ƒç”¨å¼‚å¸¸: {e}")
            yield {"error": f"æµå¼è°ƒç”¨å¼‚å¸¸: {e}"}
    
    def extract_paper_metadata(self, text: str) -> Dict[str, Any]:
        """
        ä»…ä½¿ç”¨ LLM æå–è®ºæ–‡ä¿¡æ¯ï¼›ä»»ä½•é”™è¯¯éƒ½ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸åšå…œåº•è§£æã€‚
        """
        safe_print("=" * 60)
        safe_print("å¼€å§‹è§£æè®ºæ–‡æ–‡æœ¬ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼šæ— å…œåº•ï¼‰")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        safe_print("=" * 60)

        # 1) å¿…é¡»æœ‰å¯ç”¨çš„ API Key
        if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
            raise RuntimeError("LLM ä¸å¯ç”¨ï¼šæœªé…ç½®æˆ–ä½¿ç”¨äº†å ä½ GLM_API_KEY")

        # 2) åªèµ° LLMï¼›å¤±è´¥å³æŠ›é”™
        try:
            result = self._extract_with_llm(text)
        except Exception as e:
            # é€ä¼ ä¸€å±‚ï¼Œç»™ä¸Šæ¸¸/HTTP å±‚è¿”å›æ¸…æ™°çš„ message
            raise RuntimeError(f"LLM è§£æå¤±è´¥: {e}")

        if not result:
            raise RuntimeError("LLM è¿”å›ç©ºç»“æœ")

        return result

    def _extract_with_llm(self, text: str) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨LLMè§£ææ–‡æœ¬"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡è§£æåŠ©æ‰‹ã€‚è¯·ä»ç»™å®šçš„è®ºæ–‡æ–‡æœ¬ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

1. metadataï¼ˆå…ƒæ•°æ®ï¼‰:
   - title: è®ºæ–‡æ ‡é¢˜
   - titleZh: è®ºæ–‡æ ‡é¢˜çš„ä¸­æ–‡ç¿»è¯‘
   - authors: ä½œè€…åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"name": "ä½œè€…å§“å", "affiliation": "æ‰€å±æœºæ„"}]
   - year: å‘è¡¨å¹´ä»½
   - journal: æœŸåˆŠåç§°
   - articleType: æ–‡ç« ç±»å‹ï¼ˆå¦‚ï¼šjournal, conference, preprintï¼‰
   - doi: DOI
   - tags: ç›¸å…³æ ‡ç­¾

2. abstractï¼ˆæ‘˜è¦ï¼‰:
   - zh: ä¸­æ–‡æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
   - en: è‹±æ–‡æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰

3. keywordsï¼ˆå…³é”®è¯ï¼‰:
   - å…³é”®è¯åˆ—è¡¨

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå¦‚æœæŸäº›ä¿¡æ¯æ— æ³•ä»æ–‡æœ¬ä¸­æå–ï¼Œè¯·è®¾ç½®ä¸ºnullæˆ–ç©ºæ•°ç»„ã€‚"""

        user_prompt = f"è¯·åˆ†æä»¥ä¸‹è®ºæ–‡æ–‡æœ¬ï¼Œæå–metadata, abstractå’Œkeywordsï¼š\n\n{text[:40000]}"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            # ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°è®¾ç½®
            response = self.call_llm(messages, temperature=0.6)  # ä½¿ç”¨0.6çš„æ¸©åº¦ï¼Œä¸ç¤ºä¾‹ä¸€è‡´
            
            if not response or 'choices' not in response:
                safe_print("GLM å“åº”æ ¼å¼é”™è¯¯")
                return None
                
            content = response['choices'][0]['message']['content']
            
            # å°è¯•è§£æ JSON
            try:
                # æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—ä¸­ï¼‰
                if '```json' in content:
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                elif '```' in content:
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                
                parsed_data = json.loads(content)
                return parsed_data
                
            except json.JSONDecodeError as e:
                safe_print(f"GLM è¿”å›çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {e}")
                safe_print(f"åŸå§‹å†…å®¹: {content}")
                return None
                
        except Exception as e:
            safe_print(f"æå–è®ºæ–‡å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_with_simple_parsing(self, text: str) -> Dict[str, Any]:
        """ç®€å•çš„æ–‡æœ¬è§£ææ–¹æ³•ï¼Œå½“LLMä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        import re
        
        safe_print("å¼€å§‹ç®€å•æ–‡æœ¬è§£æ")
        safe_print(f"æ–‡æœ¬è¡Œæ•°: {len(text.split(chr(10)))}")
        
        lines = text.split('\n')
        
        # æ”¹è¿›çš„æ ‡é¢˜æå–é€»è¾‘
        title = "æœªå‘½åè®ºæ–‡"
        safe_print("å¼€å§‹æå–æ ‡é¢˜ (æ£€æŸ¥å‰15è¡Œ)")
        for i, line in enumerate(lines[:15]):  # æ£€æŸ¥å‰15è¡Œ
            line = line.strip()
            # æ›´ä¸¥æ ¼çš„æ ‡é¢˜è¿‡æ»¤æ¡ä»¶
            if (len(line) > 10 and
                not line.startswith('#') and
                not line.startswith('http') and
                not any(keyword in line.lower() for keyword in ['abstract', 'introduction', 'keywords', 'doi:', 'author', 'authors', 'by', 'email', 'correspondence']) and
                # æ ‡é¢˜é€šå¸¸ä¸åŒ…å«å¤šä¸ªé€—å·åˆ†éš”çš„åå­—
                not re.search(r'\d+[,Ã—]?\d+[,Ã—]?\*?[,Ã—]?\$?\$?\{.*\}', line) and  # è¿‡æ»¤æ‰åŒ…å«ä¸Šæ ‡è„šæ³¨çš„è¡Œ
                # æ ‡é¢˜é€šå¸¸ä¸åŒ…å«é‚®ç®±æˆ–è”ç³»æ–¹å¼
                not '@' in line and not '.edu' in line and not '.org' in line):
                
                title = line
                safe_print(f"æå–åˆ°æ ‡é¢˜: {title} (æ¥è‡ªç¬¬{i+1}è¡Œ)")
                break
        
        # æ”¹è¿›çš„ä½œè€…æå–é€»è¾‘
        authors = []
        safe_print("å¼€å§‹æå–ä½œè€…ä¿¡æ¯")
        authors_found = False
        
        # åœ¨æ ‡é¢˜é™„è¿‘å¯»æ‰¾ä½œè€…ä¿¡æ¯
        title_line_index = -1
        for i, line in enumerate(lines[:15]):
            if line.strip() == title:
                title_line_index = i
                break
        
        if title_line_index >= 0:
            # æ£€æŸ¥æ ‡é¢˜åçš„å‡ è¡Œ
            for i in range(title_line_index + 1, min(title_line_index + 5, len(lines))):
                line = lines[i].strip()
                if line and not line.startswith('#'):
                    # æ£€æŸ¥æ˜¯å¦åƒä½œè€…è¡Œï¼ˆåŒ…å«å¤šä¸ªå§“åå’Œå¯èƒ½çš„æœºæ„ä¿¡æ¯ï¼‰
                    if (re.search(r'[A-Za-z][A-Za-z\s,.-]+\s[A-Za-z]', line) and
                        not 'abstract' in line.lower() and
                        not len(line) > 200):  # ä½œè€…è¡Œé€šå¸¸ä¸ä¼šå¤ªé•¿
                        
                        safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°ä½œè€…ä¿¡æ¯: {line}")
                        
                        # ä½¿ç”¨æ›´ç²¾ç¡®çš„ä½œè€…ååˆ†å‰²
                        # å»é™¤å¸¸è§çš„æœºæ„ä¿¡æ¯
                        clean_line = re.sub(r'\([^)]*\)', '', line)  # å»é™¤æ‹¬å·å†…å®¹
                        clean_line = re.sub(r'\d+[,Ã—]?\d+[,Ã—]?\*?[,Ã—]?', '', clean_line)  # å»é™¤ä¸Šæ ‡
                        
                        # æŒ‰å¸¸è§åˆ†éš”ç¬¦åˆ†å‰²
                        author_parts = re.split(r'[,\s]+and\s+|\s+and\s+|,\s*|;\s*|;', clean_line)
                        for part in author_parts:
                            part = part.strip()
                            # è¿‡æ»¤æ‰æ˜æ˜¾çš„éå§“åå†…å®¹
                            if (part and
                                len(part) > 2 and
                                len(part) < 50 and
                                not re.match(r'^\d+$', part) and  # ä¸æ˜¯çº¯æ•°å­—
                                not '@' in part and  # ä¸æ˜¯é‚®ç®±
                                not any(keyword in part.lower() for keyword in ['university', 'institute', 'department', 'school', 'college'])):
                                authors.append({"name": part, "affiliation": ""})
                                safe_print(f"  æå–ä½œè€…: {part}")
                        authors_found = True
                        break
        
        # æå–å¹´ä»½ - ä¼˜å…ˆåœ¨ç‰¹å®šä½ç½®æŸ¥æ‰¾
        year = None
        safe_print("å¼€å§‹æå–å¹´ä»½")
        
        # 1. åœ¨æ ‡é¢˜é™„è¿‘æŸ¥æ‰¾å¹´ä»½
        for i in range(max(0, title_line_index - 3), min(len(lines), title_line_index + 10)):
            year_match = re.search(r'\b(19|20)\d{2}\b', lines[i])
            if year_match:
                year = int(year_match.group())
                safe_print(f"æå–åˆ°å¹´ä»½: {year} (æ¥è‡ªç¬¬{i+1}è¡Œ)")
                break
        
        # å¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°ï¼Œæœç´¢æ•´ä¸ªæ–‡æœ¬
        if not year:
            year_match = re.search(r'\b(19|20)\d{2}\b', text)
            if year_match:
                year = int(year_match.group())
                safe_print(f"æå–åˆ°å¹´ä»½: {year} (å…¨æ–‡æœç´¢)")
        
        # æ”¹è¿›çš„æ‘˜è¦æå–é€»è¾‘
        abstract_text = ""
        abstract_found = False
        safe_print("å¼€å§‹æå–æ‘˜è¦")
        
        for i, line in enumerate(lines):
            line_lower = line.lower().strip()
            
            # å¯»æ‰¾æ‘˜è¦å¼€å§‹æ ‡è®°
            if (('abstract' in line_lower and ':' not in line_lower) or
                ('summary' in line_lower and ':' not in line_lower) or
                ('we present' in line_lower and len(line_lower) < 100)):
                
                abstract_found = True
                safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°æ‘˜è¦å¼€å§‹: {line.strip()}")
                
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦å¼€å§‹çœŸæ­£çš„æ‘˜è¦å†…å®¹
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if next_line and len(next_line) > 50:  # æ‘˜è¦é€šå¸¸æ¯”è¾ƒé•¿
                        abstract_text = next_line + " "
                        if len(abstract_text) < 300:  # å¦‚æœè¿˜ä¸å¤Ÿé•¿ï¼Œç»§ç»­è¯»å–
                            for j in range(i + 2, min(i + 10, len(lines))):
                                if lines[j].strip() and not lines[j].lower().startswith(('keywords', 'index terms', '1.', 'introduction')):
                                    abstract_text += lines[j] + " "
                                else:
                                    break
                        safe_print(f"æ‘˜è¦æå–å†…å®¹: {abstract_text[:200]}...")
                break
        
        # æå–DOI
        doi = None
        safe_print("å¼€å§‹æå–DOI")
        
        # åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­æœç´¢DOI
        doi_patterns = [
            r'doi[:\s]*(10\.\d+[^\s\n]*)',
            r'DOI[:\s]*(10\.\d+[^\s\n]*)',
            r'10\.\d+[/\w\-.,;()\s]*',
        ]
        
        for pattern in doi_patterns:
            doi_match = re.search(pattern, text, re.IGNORECASE)
            if doi_match:
                doi = doi_match.group(1) if '10.' in doi_match.group() else doi_match.group()
                # æ¸…ç†DOI
                doi = re.sub(r'[.,;]+$', '', doi)  # å»é™¤æœ«å°¾çš„æ ‡ç‚¹
                safe_print(f"æå–åˆ°DOI: {doi}")
                break
        
        # æ”¹è¿›çš„å…³é”®è¯æå–é€»è¾‘
        keywords = []
        safe_print("å¼€å§‹æå–å…³é”®è¯")
        
        for i, line in enumerate(lines):
            line_lower = line.lower().strip()
            
            # å¯»æ‰¾å…³é”®è¯æ ‡è®°
            if (('keywords' in line_lower and ':' not in line_lower) or
                ('index terms' in line_lower) or
                (line_lower.startswith('keywords') or line_lower.startswith('index terms'))):
                
                safe_print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°å…³é”®è¯: {line.strip()}")
                
                # æå–å…³é”®è¯å†…å®¹
                keywords_text = line
                if ':' in keywords_text:
                    keywords_text = keywords_text.split(':', 1)[1]
                
                # æ¸…ç†å¹¶åˆ†å‰²å…³é”®è¯
                keywords_text = re.sub(r'[â€”â€“\-]+', ',', keywords_text)  # æ›¿æ¢å„ç§ç ´æŠ˜å·
                kw_list = re.split(r'[,;]+', keywords_text)
                
                extracted_keywords = []
                for kw in kw_list:
                    kw = kw.strip()
                    # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯å…³é”®è¯çš„å†…å®¹
                    if (kw and
                        len(kw) > 2 and
                        len(kw) < 30 and
                        not re.match(r'^\d+$', kw) and  # ä¸æ˜¯çº¯æ•°å­—
                        not kw.lower().startswith(('and', 'or', 'the', 'a', 'an'))):
                        extracted_keywords.append(kw)
                
                keywords.extend(extracted_keywords)
                safe_print(f"  æå–å…³é”®è¯: {extracted_keywords}")
                break
        
        # æœŸåˆŠç±»å‹æ¨æ–­
        article_type = "journal"
        if any(keyword in text.lower() for keyword in ['conference', 'proceedings', 'workshop']):
            article_type = "conference"
        elif any(keyword in text.lower() for keyword in ['preprint', 'arxiv']):
            article_type = "preprint"
        
        result = {
            "metadata": {
                "title": title,
                "authors": authors,
                "year": year,
                "journal": "",
                "articleType": article_type,
                "doi": doi,
                "tags": []
            },
            "abstract": {
                "zh": None,  # ç®€å•è§£æä¸åŒºåˆ†è¯­è¨€
                "en": abstract_text.strip() if abstract_text.strip() else None
            },
            "keywords": keywords[:10]  # é™åˆ¶å…³é”®è¯æ•°é‡
        }
        
        safe_print("ç®€å•æ–‡æœ¬è§£æå®Œæˆ")
        safe_print("è§£æç»“æœæ‘˜è¦:")
        safe_print(f"  æ ‡é¢˜: {result['metadata']['title']}")
        safe_print(f"  ä½œè€…æ•°é‡: {len(result['metadata']['authors'])}")
        if result['metadata']['authors']:
            safe_print(f"  ä½œè€…åˆ—è¡¨: {[author['name'] for author in result['metadata']['authors']]}")
        safe_print(f"  å¹´ä»½: {result['metadata']['year']}")
        safe_print(f"  æ‘˜è¦é•¿åº¦: {len(result['abstract']['en'] or '')} å­—ç¬¦")
        safe_print(f"  DOI: {result['metadata']['doi']}")
        safe_print(f"  å…³é”®è¯æ•°é‡: {len(result['keywords'])}")
        safe_print(f"  æ–‡ç« ç±»å‹: {result['metadata']['articleType']}")
        
        return result
    
    def simple_text_chat(self, user_message: str, system_message: str = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚") -> Optional[str]:
        """
        ç®€å•çš„æ–‡æœ¬å¯¹è¯æ¥å£
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            system_message: ç³»ç»Ÿæ¶ˆæ¯
            
        Returns:
            æ¨¡å‹å›å¤å†…å®¹æˆ– None
        """
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        response = self.call_llm(messages)
        
        if response and 'choices' in response and len(response['choices']) > 0:
            return response['choices'][0]['message']['content']
        
        return None

    def parse_text_to_blocks(self, text: str, section_context: str = "") -> List[Dict[str, Any]]:
        """
        è§£ææ–‡æœ¬å¹¶ç”Ÿæˆé€‚åˆæ·»åŠ åˆ°sectionä¸­çš„blockç»“æ„
        
        Args:
            text: éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹
            section_context: sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¸®åŠ©å¤§æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œè§£æ
            
        Returns:
            è§£æåçš„blockåˆ—è¡¨
        """
        safe_print("å¼€å§‹è§£ææ–‡æœ¬ä¸ºblocks")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
            error_msg = "LLMæœåŠ¡ä¸å¯ç”¨ï¼šæœªé…ç½®GLM_API_KEYæˆ–ä½¿ç”¨äº†å ä½ç¬¦å€¼ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„GLM APIå¯†é’¥ã€‚"
            safe_print(error_msg)
            # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™é»˜å›é€€ï¼Œè®©ç”¨æˆ·çŸ¥é“é—®é¢˜æ‰€åœ¨
            raise RuntimeError(error_msg)
        
        try:
            return self._extract_blocks_with_llm(text, section_context)
        except Exception as e:
            error_msg = f"LLMè§£æå¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼Œæˆ–ç¨åé‡è¯•ã€‚"
            safe_print(error_msg)
            # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯é™é»˜å›é€€ï¼Œè®©ç”¨æˆ·çŸ¥é“é—®é¢˜æ‰€åœ¨
            raise RuntimeError(error_msg)
    
    def parse_text_to_blocks_stream(
        self,
        text: str,
        section_context: str = ""
    ):
        """
        æµå¼è§£ææ–‡æœ¬å¹¶ç”Ÿæˆé€‚åˆæ·»åŠ åˆ°sectionä¸­çš„blockç»“æ„
        
        Args:
            text: éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹
            section_context: sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¸®åŠ©å¤§æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œè§£æ
            
        Yields:
            æµå¼è§£æè¿‡ç¨‹ä¸­çš„è¿›åº¦ä¿¡æ¯
        """
        safe_print("å¼€å§‹æµå¼è§£ææ–‡æœ¬ä¸ºblocks")
        safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
            error_msg = "LLMæœåŠ¡ä¸å¯ç”¨ï¼šæœªé…ç½®GLM_API_KEYæˆ–ä½¿ç”¨äº†å ä½ç¬¦å€¼ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„GLM APIå¯†é’¥ã€‚"
            safe_print(error_msg)
            yield {"type": "error", "message": error_msg}
            return
        
        try:
            yield from self._extract_blocks_with_llm_stream(text, section_context)
        except Exception as e:
            error_msg = f"LLMè§£æå¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼Œæˆ–ç¨åé‡è¯•ã€‚"
            safe_print(error_msg)
            yield {"type": "error", "message": error_msg}

    def parse_text_to_blocks_and_save(
        self,
        text: str,
        paper_id: str,
        section_id: str,
        section_context: str = "",
        user_id: str = "",
        after_block_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è§£ææ–‡æœ¬ä¸ºblockså¹¶ç›´æ¥ä¿å­˜åˆ°è®ºæ–‡ä¸­
        
        Args:
            text: éœ€è¦è§£æçš„æ–‡æœ¬å†…å®¹
            paper_id: è®ºæ–‡ID
            section_id: section ID
            section_context: sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            user_id: ç”¨æˆ·ID
            after_block_id: åœ¨æŒ‡å®šblockåæ’å…¥ï¼Œä¸ä¼ åˆ™åœ¨æœ«å°¾æ·»åŠ 
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        try:
            safe_print("å¼€å§‹è§£ææ–‡æœ¬å¹¶ä¿å­˜åˆ°è®ºæ–‡")
            safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            safe_print(f"è®ºæ–‡ID: {paper_id}")
            safe_print(f"Section ID: {section_id}")
            
            # é¦–å…ˆè§£ææ–‡æœ¬ä¸ºblocks
            parsed_blocks = self.parse_text_to_blocks(text, section_context)
            
            if not parsed_blocks:
                return {
                    "success": False,
                    "error": "æ–‡æœ¬è§£æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„blocks"
                }
            
            safe_print(f"æˆåŠŸè§£æç”Ÿæˆ {len(parsed_blocks)} ä¸ªblocks")
            
            # è·å–paperæœåŠ¡æ¥ä¿å­˜
            from ..services.paperService import get_paper_service
            paper_service = get_paper_service()
            
            # è·å–å½“å‰è®ºæ–‡æ•°æ®
            paper = paper_service.paper_model.find_by_id(paper_id)
            if not paper:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ°æŒ‡å®šçš„è®ºæ–‡: {paper_id}"
                }
            
            # æŸ¥æ‰¾ç›®æ ‡section
            sections = paper.get("sections", [])
            target_section = None
            section_index = -1
            
            for i, section in enumerate(sections):
                if section.get("id") == section_id:
                    target_section = section
                    section_index = i
                    break
            
            if not target_section:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ°æŒ‡å®šçš„section: {section_id}"
                }
            
            # ç¡®ä¿sectionæœ‰contentå­—æ®µ
            if "content" not in target_section:
                target_section["content"] = []
            
            # æ ¹æ®after_block_idç¡®å®šæ’å…¥ä½ç½®
            current_blocks = target_section["content"]
            insert_index = len(current_blocks)  # é»˜è®¤åœ¨æœ«å°¾
            
            if after_block_id:
                for i, block in enumerate(current_blocks):
                    if block.get("id") == after_block_id:
                        insert_index = i + 1  # æ’å…¥åˆ°æŒ‡å®šblockåé¢
                        break
            
            # ä½¿ç”¨MongoDBçš„åŸå­æ›´æ–°æ“ä½œï¼Œé¿å…æ›¿æ¢æ•´ä¸ªsectionsæ•°ç»„
            safe_print(f"åœ¨ä½ç½® {insert_index} æ’å…¥ {len(parsed_blocks)} ä¸ªblocks")
            
            # æ„å»ºæ›´æ–°æ“ä½œï¼šä½¿ç”¨$pushæ“ä½œç¬¦å°†æ–°blocksæ’å…¥åˆ°æŒ‡å®šä½ç½®
            if insert_index == len(current_blocks):
                # å¦‚æœåœ¨æœ«å°¾æ·»åŠ ï¼Œä½¿ç”¨$push
                update_operation = {
                    "$push": {
                        f"sections.{section_index}.content": {
                            "$each": parsed_blocks
                        }
                    }
                }
            else:
                # å¦‚æœåœ¨ä¸­é—´æ’å…¥ï¼Œä½¿ç”¨$pushé…åˆ$positionï¼Œé¿å…æ›¿æ¢æ•´ä¸ªæ•°ç»„
                update_operation = {
                    "$push": {
                        f"sections.{section_index}.content": {
                            "$each": parsed_blocks,
                            "$position": insert_index
                        }
                    }
                }
            
            # æ‰§è¡ŒåŸå­æ›´æ–°
            if paper_service.paper_model.update(paper_id, update_operation):
                updated_paper = paper_service.paper_model.find_by_id(paper_id)
                return {
                    "success": True,
                    "message": f"æˆåŠŸå‘sectionæ·»åŠ äº†{len(parsed_blocks)}ä¸ªblocks",
                    "data": {
                        "paper": updated_paper,
                        "addedBlocks": parsed_blocks,
                        "sectionId": section_id,
                        "totalBlocks": len(parsed_blocks)
                    }
                }
            else:
                return {
                    "success": False,
                    "error": "æ›´æ–°è®ºæ–‡å¤±è´¥"
                }
            
        except Exception as e:
            safe_print(f"è§£æå¹¶ä¿å­˜å¤±è´¥: {e}")
            import traceback
            safe_print(traceback.format_exc())
            return {
                "success": False,
                "error": f"è§£æå¹¶ä¿å­˜å¤±è´¥: {str(e)}"
            }

    def _ensure_bilingual_inline(self,inline_items):
        """å°† InlineContent æ•°ç»„ä¸­ç¼ºå¤±è¯­è¨€çš„æ–‡æœ¬å¤åˆ¶ä¸ºåŒå†…å®¹ï¼Œç¡®ä¿ en/zh éƒ½æœ‰å€¼"""
        if not isinstance(inline_items, list):
            return []
        normalized = []
        for item in inline_items:
            if isinstance(item, dict):
                normalized.append(item)
            else:
                normalized.append({"type": "text", "text": str(item)})
        return normalized

    def _fill_missing_languages(self,block):
        """åœ¨ block çš„ content ä¸­è¡¥å…¨ en/zhï¼Œè‹¥ç¼ºå¤±åˆ™ä»¥å¦ä¸€è¯­è¨€å†…å®¹æˆ–ç©ºæ•°ç»„å›å¡«"""
        content = block.get("content")
        if not isinstance(content, dict):
            return block
        en = self._ensure_bilingual_inline(content.get("en"))
        zh = self._ensure_bilingual_inline(content.get("zh"))
        if not en and zh:
            en = [dict(item) for item in zh]
        if not zh and en:
            zh = [dict(item) for item in en]
        block["content"] = {"en": en, "zh": zh}
        return block

    def _extract_blocks_with_llm(self, text: str, section_context: str) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨LLMè§£æMarkdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºç»“æ„åŒ–çš„blockæ•°ç»„
        
        Args:
            text: è¦è§£æçš„Markdownæ–‡æœ¬
            section_context: å½“å‰sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            List[Dict[str, Any]]: è§£æåçš„blockåˆ—è¡¨
        """
        import json
        import re
        from typing import List, Dict, Any

        PARSER_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡Markdownè§£æåŠ©æ‰‹ï¼Œè´Ÿè´£å°†Markdownæ ¼å¼çš„è®ºæ–‡æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONæ•°æ®ã€‚

    ## æ ¸å¿ƒä»»åŠ¡
    è§£æMarkdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡ï¼Œè¾“å‡ºç¬¦åˆè§„èŒƒçš„JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªå†…å®¹å—(block)ã€‚

    ## é‡è¦è¦æ±‚
    1. **å¿…é¡»åŒæ—¶åŒ…å«ä¸­è‹±æ–‡å†…å®¹** - æ¯ä¸ªblockçš„contentå­—æ®µå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„
    2. **å¿…é¡»è¾“å‡ºçº¯JSONæ•°ç»„**ï¼Œä»¥[å¼€å¤´ï¼Œä»¥]ç»“å°¾
    3. **ä¸åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—ã€æ³¨é‡Šæˆ–markdownä»£ç å—æ ‡è®°**
    4. **æ‰€æœ‰æ–‡æœ¬å†…å®¹ä½¿ç”¨InlineContentæ•°ç»„æ ¼å¼**

    ## Markdownè¯†åˆ«è§„åˆ™

    ### æ ‡é¢˜ (heading)
    - # å¼€å¤´çš„æ˜¯æ ‡é¢˜ #å¯èƒ½æœ‰å¤šä¸ª
    - 1.ä¸ºä¸€çº§æ ‡é¢˜ 1.1ä¸ºäºŒçº§æ ‡é¢˜ 1.1.1ä¸ºä¸‰çº§æ ‡é¢˜
    - ä»¥æ­¤ç±»æ¨è‡³å…­çº§æ ‡é¢˜
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "heading",
    "level": 2,
    "content": {
        "en": [{"type": "text", "content": "Introduction"}]
    }
    }

    ### æ®µè½ (paragraph)
    - éç‰¹æ®Šæ ¼å¼çš„è¿ç»­æ–‡æœ¬è¡Œ
    - ç©ºè¡Œåˆ†éš”ä¸åŒæ®µè½
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "paragraph",
    "content": {
        "en": [{"type": "text", "content": "This is a paragraph."}]
    }
    }

    ### è¡Œé—´å…¬å¼ (math)
    - ç‹¬ç«‹æˆè¡Œçš„ $$...$$ æˆ– \\[...\\] æ ¼å¼
    - **é‡è¦**ï¼šå»é™¤\\tag{...}ç­‰ç¼–å·ï¼Œåªä¿ç•™å…¬å¼æœ¬ä½“
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "math",
    "latex": "E = mc^2"
    }

    ### è¡Œå†…å…¬å¼ (inline-math)
    - æ–‡æœ¬ä¸­çš„ $...$ æˆ– \\(...\\) æ ¼å¼
    - **å¿…é¡»ä½¿ç”¨latexå­—æ®µï¼Œä¸èƒ½ä½¿ç”¨contentå­—æ®µ**
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {"type": "inline-math", "latex": "x^2 + y^2 = z^2"}

    ### æœ‰åºåˆ—è¡¨ (ordered-list)
    - ä»¥ 1. , 2. ç­‰æ•°å­—å¼€å¤´
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "ordered-list",
    "items": [
        {"content": {"en": [{"type": "text", "content": "First item"}]}},
        {"content": {"en": [{"type": "text", "content": "Second item"}]}}
    ]
    }

    ### æ— åºåˆ—è¡¨ (unordered-list)
    - ä»¥ - , * , + å¼€å¤´
    - è¾“å‡ºæ ¼å¼åŒæœ‰åºåˆ—è¡¨ï¼Œtypeä¸º"unordered-list"

    ### ä»£ç å— (code)
    - ä¸‰ä¸ªåå¼•å·åŒ…å›´çš„ä»£ç å—
    - è¯†åˆ«è¯­è¨€æ ‡è®°ï¼ˆå¦‚pythonï¼‰
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "code",
    "language": "python",
    "code": "def hello():\\n    print('Hello')"
    }

    ### è¡¨æ ¼ (table)
    - Markdownè¡¨æ ¼æ ¼å¼ï¼š|åˆ—1|åˆ—2| 
    - HTMLè¡¨æ ¼æ ¼å¼ï¼š<table>...</table>
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "table",
    "headers": ["Column 1", "Column 2"],
    "rows": [
        ["Cell 1", "Cell 2"],
        ["Cell 3", "Cell 4"]
    ]
    }

    ### å¼•ç”¨ (quote)
    - ä»¥ > å¼€å¤´çš„è¡Œ
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "quote",
    "content": {
        "en": [{"type": "text", "content": "This is a quote"}]
    }
    }

    ### åˆ†å‰²çº¿ (divider)
    - ---, ***, ___ ç­‰
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {"type": "divider"}

    ## ç‰¹æ®Šå¤„ç†è§„åˆ™

    ### å¼•ç”¨åˆ é™¤
    **å®Œå…¨åˆ é™¤**ä»¥ä¸‹å†…å®¹ï¼Œä¸è¦åŒ…å«åœ¨è¾“å‡ºä¸­ï¼š
    - å‚è€ƒæ–‡çŒ®å¼•ç”¨ï¼šå¦‚ [1], [2,3], [Smith et al., 2020]
    - å›¾ç‰‡å¼•ç”¨ï¼šå¦‚ Fig. 1, Figure 2, å›¾1
    - è¡¨æ ¼å¼•ç”¨ï¼šå¦‚ Table 1, Tab. 2, è¡¨1
    - å…¬å¼å¼•ç”¨ï¼šå¦‚ Eq. (1), Equation 2, å¼(1)
    - è„šæ³¨æ ‡è®°ï¼šå¦‚ [^1], [^note]
    - äº¤å‰å¼•ç”¨ï¼šå¦‚ see Section 2, as shown in Chapter 3

    ### æ–‡æœ¬å¤„ç†
    æ··åˆæ–‡æœ¬å’Œå…¬å¼æ—¶ï¼Œå°†å…¬å¼è¯†åˆ«ä¸ºinline-mathç±»å‹ã€‚ä¾‹å¦‚ï¼š
    è¾“å…¥ï¼š"The equation $x^2 + y^2 = z^2$ represents..."
    è¾“å‡ºï¼š[
    {"type": "text", "content": "The equation "},
    {"type": "inline-math", "latex": "x^2 + y^2 = z^2"},
    {"type": "text", "content": " represents..."}
    ]

    ## å®Œæ•´ç¤ºä¾‹

    è¾“å…¥Markdownï¼š
    ## Introduction

    Machine learning has revolutionized many fields. The basic equation $y = wx + b$ represents a linear model.

    $$
    L = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 \\tag{1}
    $$

    Key advantages include:
    - High accuracy
    - Fast processing

    | Method | Accuracy |
    |--------|----------|
    | SVM    | 95%      |
    | CNN    | 98%      |

    è¾“å‡ºJSONï¼š
    [
    {
        "type": "heading",
        "level": 2,
        "content": {
        "en": [{"type": "text", "content": "Introduction"}]
        }
    },
    {
        "type": "paragraph",
        "content": {
        "en": [
            {"type": "text", "content": "Machine learning has revolutionized many fields. The basic equation "},
            {"type": "inline-math", "latex": "y = wx + b"},
            {"type": "text", "content": " represents a linear model."}
        ]
        }
    },
    {
        "type": "math",
        "latex": "L = \\\\frac{1}{n}\\\\sum_{i=1}^{n}(y_i - \\\\hat{y}_i)^2"
    },
    {
        "type": "paragraph",
        "content": {
        "en": [{"type": "text", "content": "Key advantages include:"}]
        }
    },
    {
        "type": "unordered-list",
        "items": [
        {"content": {"en": [{"type": "text", "content": "High accuracy"}]}},
        {"content": {"en": [{"type": "text", "content": "Fast processing"}]}}
        ]
    },
    {
        "type": "table",
        "headers": ["Method", "Accuracy"],
        "rows": [
        ["SVM", "95%"],
        ["CNN", "98%"]
        ]
    }
    ]

    ## é‡è¦æé†’
    1. **åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹**
    2. **inline-mathå¿…é¡»ç”¨latexå­—æ®µï¼Œä¸èƒ½ç”¨contentå­—æ®µ**
    3. **åˆ é™¤æ‰€æœ‰å¼•ç”¨æ ‡è®°**
    4. **ä¿æŒå­¦æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§**"""

        # ç§»é™¤å•ç‹¬çš„ç¿»è¯‘æç¤ºè¯ï¼Œå› ä¸ºç°åœ¨è§£æå’Œç¿»è¯‘åˆå¹¶ä¸ºä¸€æ¬¡è°ƒç”¨
        TRANSLATION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç¿»è¯‘ä¸“å®¶ã€‚

    ## ä»»åŠ¡
    å°†æä¾›çš„JSONæ•°ç»„ä¸­çš„è‹±æ–‡å†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œæ·»åŠ åˆ°zhå­—æ®µä¸­ã€‚

    ## ç¿»è¯‘è¦æ±‚
    1. ä¿æŒå­¦æœ¯æœ¯è¯­çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
    2. æ•°å­¦å…¬å¼ã€ä»£ç ã€å˜é‡åç­‰ä¿æŒåŸæ ·
    3. ä½¿ç”¨è§„èŒƒçš„å­¦æœ¯ä¸­æ–‡è¡¨è¾¾
    4. ä¿æŒåŸæ–‡çš„è¯­ä¹‰å’Œé€»è¾‘ç»“æ„

    ## è¾“å…¥æ ¼å¼
    ä½ ä¼šæ”¶åˆ°ä¸€ä¸ªåŒ…å«è‹±æ–‡å†…å®¹çš„JSONæ•°ç»„ã€‚

    ## è¾“å‡ºæ ¼å¼
    è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªåŒ…å«contentå­—æ®µçš„å¯¹è±¡éƒ½åº”è¯¥åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªå­—æ®µã€‚

    **é‡è¦**ï¼šåªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—ã€‚"""

        # ä½¿ç”¨å…¨å±€çš„safe_printå‡½æ•°ï¼Œé¿å…é‡å¤å®šä¹‰

        def _parse_markdown():
            """ä½¿ç”¨LLMè§£æMarkdownæ–‡æœ¬"""
            safe_print("ğŸš€ å¼€å§‹è§£æMarkdownæ–‡æœ¬")
            
            # é¢„å¤„ç†ï¼šæ¸…ç†æ–‡æœ¬
            cleaned_text = text.strip()
            
            # æ›¿æ¢è¡Œå†…å…¬å¼æ ¼å¼ $...$ -> \(...\)
            cleaned_text = re.sub(r'\$([^$]+)\$', r'\\(\1\\)', cleaned_text)
            
            # æ›¿æ¢è¡Œé—´å…¬å¼æ ¼å¼ $...$ -> \\[...\\]
            cleaned_text = re.sub(r'\$\$([^$]+)\$\$', r'\\[\1\\]', cleaned_text, flags=re.DOTALL)
            
            # é™åˆ¶æ–‡æœ¬é•¿åº¦
            if len(cleaned_text) > 30000:
                safe_print(f"âš ï¸ æ–‡æœ¬è¿‡é•¿({len(cleaned_text)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³30000å­—ç¬¦")
                cleaned_text = cleaned_text[:30000]
            
            user_prompt = f"""è¯·è§£æä»¥ä¸‹Markdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡æ–‡æœ¬ï¼Œè¾“å‡ºJSONæ•°ç»„ï¼š

    {cleaned_text}

    è®°ä½ï¼š
    1. åªè¾“å‡ºJSONæ•°ç»„
    2. åˆ é™¤æ‰€æœ‰å¼•ç”¨
    3. inline-mathä½¿ç”¨latexå­—æ®µ
    4. å»é™¤å…¬å¼ç¼–å·å¦‚\\tag{{}}
    5. **é‡è¦ï¼šå¿…é¡»åŒæ—¶åŒ…å«ä¸­è‹±æ–‡å†…å®¹ï¼Œæ¯ä¸ªblockçš„contentå­—æ®µå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„**"""

            messages = [
                {"role": "system", "content": PARSER_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            safe_print("ğŸ“¤ å‘é€è§£æè¯·æ±‚...")
            response = self.call_llm(messages, temperature=0.1, max_tokens=50000)
            
            if not response or "choices" not in response:
                raise Exception("LLMå“åº”æ— æ•ˆ")
            
            content = response["choices"][0]["message"]["content"]
            
            # æ¸…ç†å“åº”å†…å®¹
            content = content.strip()
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            elif "```" in content:
                start = content.find("```") + 3
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            
            try:
                return json.loads(content)
            except json.JSONDecodeError as e:
                safe_print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                safe_print(f"å“åº”å†…å®¹: {content[:500]}...")
                
                # ä¿å­˜é”™è¯¯å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
                import os
                import traceback
                from datetime import datetime
                
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ç›®å½•ä½ç½®
                possible_dirs = [
                    "error_logs",
                    "apps/api/error_logs",
                    "apps/api/neuink/error_logs",
                    "/tmp/error_logs" if os.name != 'nt' else "C:\\temp\\error_logs"
                ]
                
                error_dir = None
                for dir_path in possible_dirs:
                    try:
                        if not os.path.exists(dir_path):
                            os.makedirs(dir_path, exist_ok=True)
                        # æµ‹è¯•æ˜¯å¦å¯ä»¥å†™å…¥
                        test_file = os.path.join(dir_path, "test_write.tmp")
                        with open(test_file, 'w') as f:
                            f.write("test")
                        os.remove(test_file)
                        error_dir = dir_path
                        safe_print(f"âœ… ä½¿ç”¨é”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                        break
                    except Exception as dir_error:
                        safe_print(f"âš ï¸ æ— æ³•ä½¿ç”¨ç›®å½• {dir_path}: {dir_error}")
                        continue
                
                if not error_dir:
                    # å¦‚æœæ‰€æœ‰é¢„è®¾ç›®å½•éƒ½ä¸å¯ç”¨ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•åˆ›å»º
                    try:
                        error_dir = os.getcwd()
                        safe_print(f"âš ï¸ ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºé”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                    except Exception as cwd_error:
                        safe_print(f"âŒ æ— æ³•è·å–å½“å‰ç›®å½•: {cwd_error}")
                        error_dir = "."
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                error_file = os.path.join(error_dir, f"json_parse_error_sync_{timestamp}.txt")
                
                try:
                    with open(error_file, 'w', encoding='utf-8') as f:
                        f.write(f"JSONè§£æé”™è¯¯æ—¶é—´: {datetime.now()}\n")
                        f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                        f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                        f.write(f"é”™è¯¯ä½ç½®: line {e.lineno}, column {e.colno}, character {e.pos}\n")
                        f.write(f"é”™è¯¯è¯¦æƒ…: {e.msg if hasattr(e, 'msg') else 'æ— è¯¦ç»†ä¿¡æ¯'}\n")
                        f.write("=" * 50 + "\n")
                        f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                        f.write(content)
                        f.write("\n" + "=" * 50 + "\n")
                        f.write(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\n")
                        f.write(f"å‰500å­—ç¬¦é¢„è§ˆ: {content[:500]}\n")
                        f.write(f"å500å­—ç¬¦é¢„è§ˆ: {content[-500:] if len(content) > 500 else 'æ— '}\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("é”™è¯¯ä½ç½®ä¸Šä¸‹æ–‡:\n")
                        if hasattr(e, 'pos') and e.pos is not None:
                            start_pos = max(0, e.pos - 100)
                            end_pos = min(len(content), e.pos + 100)
                            f.write(f"ä½ç½® {e.pos} é™„è¿‘å†…å®¹:\n")
                            f.write(repr(content[start_pos:end_pos]))
                            f.write("\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("å®Œæ•´å †æ ˆè·Ÿè¸ª:\n")
                        f.write(traceback.format_exc())
                    safe_print(f"âœ… é”™è¯¯å†…å®¹å·²ä¿å­˜åˆ°: {error_file}")
                    
                    # å°è¯•åœ¨Windowsæ¡Œé¢ä¹Ÿä¿å­˜ä¸€ä»½
                    try:
                        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
                        if os.path.exists(desktop_path):
                            desktop_error_file = os.path.join(desktop_path, f"neuink_json_error_{timestamp}.txt")
                            with open(desktop_error_file, 'w', encoding='utf-8') as f:
                                f.write(f"NeuInk JSONè§£æé”™è¯¯ - {datetime.now()}\n")
                                f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                                f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                                f.write("=" * 50 + "\n")
                                f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                                f.write(content)
                            safe_print(f"âœ… é”™è¯¯å‰¯æœ¬å·²ä¿å­˜åˆ°æ¡Œé¢: {desktop_error_file}")
                    except Exception as desktop_error:
                        safe_print(f"âš ï¸ æ— æ³•ä¿å­˜åˆ°æ¡Œé¢: {desktop_error}")
                        
                except Exception as save_error:
                    safe_print(f"âŒ ä¿å­˜é”™è¯¯æ—¥å¿—å¤±è´¥: {save_error}")
                    safe_print(f"âŒ å°è¯•ä¿å­˜çš„è·¯å¾„: {error_file}")
                    safe_print(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
                raise

        def _add_translations(blocks):
            """ä¸ºblocksæ·»åŠ ä¸­æ–‡ç¿»è¯‘"""
            safe_print("ğŸŒ å¼€å§‹æ·»åŠ ä¸­æ–‡ç¿»è¯‘")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘
            needs_translation = False
            for block in blocks:
                if "content" in block and isinstance(block["content"], dict):
                    if "en" in block["content"] and "zh" not in block["content"]:
                        needs_translation = True
                        break
            
            if not needs_translation:
                safe_print("âœ… æ‰€æœ‰å†…å®¹å·²æœ‰ä¸­æ–‡ç¿»è¯‘ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤")
                return blocks
            
            # æ‰¹é‡å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†10ä¸ªblock
            batch_size = 10
            for i in range(0, len(blocks), batch_size):
                batch = blocks[i:i+batch_size]
                
                # åªé€‰æ‹©éœ€è¦ç¿»è¯‘çš„blocks
                batch_to_translate = []
                for block in batch:
                    if "content" in block or (block["type"] in ["ordered-list", "unordered-list"] and "items" in block):
                        batch_to_translate.append(block)
                
                if not batch_to_translate:
                    continue
                
                user_prompt = f"""è¯·ä¸ºä»¥ä¸‹JSONæ•°ç»„ä¸­çš„è‹±æ–‡å†…å®¹æ·»åŠ ä¸­æ–‡ç¿»è¯‘ï¼š

    {json.dumps(batch_to_translate, ensure_ascii=False, indent=2)}

    åªè¾“å‡ºå®Œæ•´çš„JSONæ•°ç»„ã€‚"""

                messages = [
                    {"role": "system", "content": TRANSLATION_PROMPT},
                    {"role": "user", "content": user_prompt}
                ]
                
                try:
                    response = self.call_llm(messages, temperature=0.1, max_tokens=50000)
                    
                    # å¢å¼ºçš„é”™è¯¯æ£€æŸ¥
                    if not response:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: APIå“åº”ä¸ºç©º")
                        continue
                        
                    if "choices" not in response:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: å“åº”æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘choices")
                        continue
                        
                    if not response["choices"]:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: choicesæ•°ç»„ä¸ºç©º")
                        continue
                    
                    if "message" not in response["choices"][0]:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: ç¼ºå°‘messageå­—æ®µ")
                        continue
                    
                    content = response["choices"][0]["message"]["content"]
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
                    if not content or not content.strip():
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: å“åº”å†…å®¹ä¸ºç©º")
                        continue
                    
                    # æ¸…ç†å“åº”å†…å®¹
                    original_content = content  # ä¿å­˜åŸå§‹å†…å®¹ç”¨äºè°ƒè¯•
                    content = content.strip()
                    
                    # æå–JSONå†…å®¹ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                    json_extracted = False
                    if "```json" in content:
                        start = content.find("```json") + 7
                        end = content.find("```", start)
                        if end != -1:
                            content = content[start:end].strip()
                            json_extracted = True
                    elif "```" in content:
                        start = content.find("```") + 3
                        end = content.find("```", start)
                        if end != -1:
                            content = content[start:end].strip()
                            json_extracted = True
                    
                    # æ£€æŸ¥æ¸…ç†åçš„å†…å®¹æ˜¯å¦ä¸ºç©º
                    if not content:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: æå–JSONåå†…å®¹ä¸ºç©º")
                        safe_print(f"åŸå§‹å“åº”: {original_content[:200]}...")
                        continue
                    
                    # å°è¯•è§£æJSON
                    try:
                        translated_batch = json.loads(content)
                    except json.JSONDecodeError as json_e:
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: JSONè§£æé”™è¯¯ {json_e}")
                        safe_print(f"è§£æå†…å®¹: {content[:200]}...")
                        safe_print(f"åŸå§‹å“åº”: {original_content[:200]}...")
                        continue
                    
                    # éªŒè¯è§£æç»“æœ
                    if not isinstance(translated_batch, list):
                        safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: è¿”å›çš„ä¸æ˜¯æ•°ç»„æ ¼å¼")
                        continue
                    
                    # æ›´æ–°åŸå§‹blocksä¸­å¯¹åº”çš„å†…å®¹
                    translated_idx = 0
                    updated_count = 0
                    for j in range(len(batch)):
                        if i+j < len(blocks):
                            block = blocks[i+j]
                            # åªæ›´æ–°è¢«ç¿»è¯‘çš„blocks
                            if "content" in block or (block["type"] in ["ordered-list", "unordered-list"] and "items" in block):
                                if translated_idx < len(translated_batch):
                                    blocks[i+j] = translated_batch[translated_idx]
                                    translated_idx += 1
                                    updated_count += 1
                    
                    if updated_count == 0:
                        safe_print(f"âš ï¸ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1}: æ²¡æœ‰blocksè¢«æ›´æ–°")
                    else:
                        safe_print(f"âœ… å®Œæˆæ‰¹æ¬¡ {i//batch_size + 1} çš„ç¿»è¯‘ï¼Œæ›´æ–°äº† {updated_count} ä¸ªblocks")
                        
                except requests.exceptions.RequestException as req_e:
                    safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: ç½‘ç»œè¯·æ±‚é”™è¯¯ {req_e}")
                    continue
                except Exception as e:
                    safe_print(f"âŒ ç¿»è¯‘æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: æœªçŸ¥é”™è¯¯ {e}")
                    safe_print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    continue
            
            return blocks

        def _fix_and_validate(blocks):
            """ä¿®å¤å’ŒéªŒè¯blocks"""
            # å¯¼å…¥å¿…è¦çš„å·¥å…·å‡½æ•°
            try:
                from ..utils.common import generate_id, get_current_time
            except ImportError:
                # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                import uuid
                from datetime import datetime
                
                def generate_id():
                    return str(uuid.uuid4())
                
                def get_current_time():
                    return datetime.now()
            
            validated_blocks = []
            
            for idx, block in enumerate(blocks):
                try:
                    if not isinstance(block, dict) or "type" not in block:
                        safe_print(f"â­ï¸ è·³è¿‡æ— æ•ˆblock {idx}: ç¼ºå°‘typeå­—æ®µ")
                        continue
                    
                    # æ·»åŠ å¿…éœ€å­—æ®µ
                    if "id" not in block:
                        block["id"] = generate_id()
                    if "createdAt" not in block:
                        block["createdAt"] = get_current_time().isoformat()
                    
                    # ç¡®ä¿contentå­—æ®µæ ¼å¼æ­£ç¡®
                    if "content" in block:
                        content = block["content"]
                        if isinstance(content, dict):
                            # ç¡®ä¿æœ‰enå’Œzhå­—æ®µ
                            if "en" not in content:
                                content["en"] = []
                            if "zh" not in content:
                                # å¦‚æœæ²¡æœ‰zhå­—æ®µï¼Œå¤åˆ¶ençš„å†…å®¹
                                content["zh"] = content.get("en", []).copy()
                            
                            # ä¿®å¤inline-mathå­—æ®µ
                            for lang in ["en", "zh"]:
                                if lang in content and isinstance(content[lang], list):
                                    for item in content[lang]:
                                        if isinstance(item, dict) and item.get("type") == "inline-math":
                                            # ç¡®ä¿ä½¿ç”¨latexå­—æ®µè€Œä¸æ˜¯contentå­—æ®µ
                                            if "content" in item and "latex" not in item:
                                                item["latex"] = item.pop("content")
                                                safe_print(f"ğŸ”§ ä¿®å¤block {idx} çš„inline-mathå­—æ®µ")
                    
                    # å¤„ç†åˆ—è¡¨é¡¹
                    if block["type"] in ["ordered-list", "unordered-list"]:
                        if "items" in block and isinstance(block["items"], list):
                            for item_idx, item in enumerate(block["items"]):
                                if "content" in item and isinstance(item["content"], dict):
                                    # ç¡®ä¿åˆ—è¡¨é¡¹ä¹Ÿæœ‰åŒè¯­å†…å®¹
                                    if "en" not in item["content"]:
                                        item["content"]["en"] = []
                                    if "zh" not in item["content"]:
                                        item["content"]["zh"] = item["content"].get("en", []).copy()
                                    
                                    # ä¿®å¤åˆ—è¡¨é¡¹ä¸­çš„inline-math
                                    for lang in ["en", "zh"]:
                                        if lang in item["content"] and isinstance(item["content"][lang], list):
                                            for content_item in item["content"][lang]:
                                                if isinstance(content_item, dict) and content_item.get("type") == "inline-math":
                                                    if "content" in content_item and "latex" not in content_item:
                                                        content_item["latex"] = content_item.pop("content")
                    
                    # å¤„ç†è¡¨æ ¼
                    if block["type"] == "table":
                        # ç¡®ä¿è¡¨æ ¼æœ‰å¿…è¦çš„å­—æ®µ
                        if "headers" not in block:
                            block["headers"] = []
                        if "rows" not in block:
                            block["rows"] = []
                        # è¡¨æ ¼çš„captionä¹Ÿéœ€è¦åŒè¯­
                        if "caption" in block and isinstance(block["caption"], dict):
                            if "en" not in block["caption"]:
                                block["caption"]["en"] = []
                            if "zh" not in block["caption"]:
                                block["caption"]["zh"] = block["caption"].get("en", []).copy()
                    
                    # å¤„ç†æ•°å­¦å…¬å¼å—
                    if block["type"] == "math":
                        if "latex" in block:
                            # å»é™¤\tag{}ç¼–å·
                            latex = block["latex"]
                            latex = re.sub(r'\\tag\{[^}]*\}', '', latex)
                            # å»é™¤å¤šä½™çš„ç©ºæ ¼
                            latex = re.sub(r'\s+', ' ', latex).strip()
                            block["latex"] = latex
                    
                    validated_blocks.append(block)
                    safe_print(f"âœ… éªŒè¯block {idx}: type={block['type']}")
                    
                except Exception as e:
                    safe_print(f"âŒ éªŒè¯block {idx} å¤±è´¥: {e}")
                    continue
            
            return validated_blocks

        # ä¸»æ‰§è¡Œæµç¨‹
        try:
            # æ­¥éª¤1ï¼šè§£æMarkdownï¼ˆç°åœ¨åŒ…å«ç¿»è¯‘ï¼‰
            blocks = _parse_markdown()
            safe_print(f"âœ… è§£æå®Œæˆï¼Œå¾—åˆ° {len(blocks)} ä¸ªblocks")
            
            # æ­¥éª¤2ï¼šä¿®å¤å’ŒéªŒè¯
            validated_blocks = _fix_and_validate(blocks)
            safe_print(f"âœ… æœ€ç»ˆç”Ÿæˆ {len(validated_blocks)} ä¸ªæœ‰æ•ˆblocks")
            
            return validated_blocks
            
        except Exception as e:
            safe_print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            safe_print(traceback.format_exc())
            raise Exception(f"LLMè§£æå¤±è´¥: {e}")

    def _extract_blocks_with_llm_stream(self, text: str, section_context: str = ""):
        """
        ä½¿ç”¨LLMæµå¼è§£æMarkdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºç»“æ„åŒ–çš„blockæ•°ç»„
        
        Args:
            text: è¦è§£æçš„Markdownæ–‡æœ¬
            section_context: å½“å‰sectionçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Yields:
            æµå¼è§£æè¿‡ç¨‹ä¸­çš„è¿›åº¦ä¿¡æ¯
        """
        import json
        import re
        from typing import List, Dict, Any

        PARSER_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡Markdownè§£æåŠ©æ‰‹ï¼Œè´Ÿè´£å°†Markdownæ ¼å¼çš„è®ºæ–‡æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONæ•°æ®ã€‚

    ## æ ¸å¿ƒä»»åŠ¡
    è§£æMarkdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡ï¼Œè¾“å‡ºç¬¦åˆè§„èŒƒçš„JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªå†…å®¹å—(block)ã€‚

    ## é‡è¦è¦æ±‚
    1. **å¿…é¡»åŒæ—¶åŒ…å«ä¸­è‹±æ–‡å†…å®¹** - æ¯ä¸ªblockçš„contentå­—æ®µå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„
    2. **å¿…é¡»è¾“å‡ºçº¯JSONæ•°ç»„**ï¼Œä»¥[å¼€å¤´ï¼Œä»¥]ç»“å°¾
    3. **ä¸åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—ã€æ³¨é‡Šæˆ–markdownä»£ç å—æ ‡è®°**
    4. **æ‰€æœ‰æ–‡æœ¬å†…å®¹ä½¿ç”¨InlineContentæ•°ç»„æ ¼å¼**

    ## Markdownè¯†åˆ«è§„åˆ™

    ### æ ‡é¢˜ (heading)
    - #å¼€å¤´ä¸ºæ ‡é¢˜ï¼Œå¦‚æœæœ‰ç¼–å·ï¼Œä¾‹å¦‚3.1ä¸ºäºŒçº§æ ‡é¢˜ 3.1.2ä¸ºä¸‰çº§æ ‡é¢˜
    - ä»¥æ­¤ç±»æ¨è‡³å…­çº§æ ‡é¢˜
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "heading",
    "level": 2,
    "content": {
        "en": [{"type": "text", "content": "Introduction"}]
    }
    }

    ### æ®µè½ (paragraph)
    - éç‰¹æ®Šæ ¼å¼çš„è¿ç»­æ–‡æœ¬è¡Œ
    - ç©ºè¡Œåˆ†éš”ä¸åŒæ®µè½
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "paragraph",
    "content": {
        "en": [{"type": "text", "content": "This is a paragraph."}]
    }
    }

    ### è¡Œé—´å…¬å¼ (math)
    - ç‹¬ç«‹æˆè¡Œçš„ $$...$$ æˆ– \\[...\\] æ ¼å¼
    - **é‡è¦**ï¼šå»é™¤\\tag{...}ç­‰ç¼–å·ï¼Œåªä¿ç•™å…¬å¼æœ¬ä½“
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "math",
    "latex": "E = mc^2"
    }

    ### è¡Œå†…å…¬å¼ (inline-math)
    - æ–‡æœ¬ä¸­çš„ $...$ æˆ– \\(...\\) æ ¼å¼
    - **å¿…é¡»ä½¿ç”¨latexå­—æ®µï¼Œä¸èƒ½ä½¿ç”¨contentå­—æ®µ**
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {"type": "inline-math", "latex": "x^2 + y^2 = z^2"}

    ### æœ‰åºåˆ—è¡¨ (ordered-list)
    - ä»¥ 1. , 2. ç­‰æ•°å­—å¼€å¤´
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "ordered-list",
    "items": [
        {"content": {"en": [{"type": "text", "content": "First item"}]}},
        {"content": {"en": [{"type": "text", "content": "Second item"}]}}
    ]
    }

    ### æ— åºåˆ—è¡¨ (unordered-list)
    - ä»¥ - , * , + å¼€å¤´
    - è¾“å‡ºæ ¼å¼åŒæœ‰åºåˆ—è¡¨ï¼Œtypeä¸º"unordered-list"

    ### ä»£ç å— (code)
    - ä¸‰ä¸ªåå¼•å·åŒ…å›´çš„ä»£ç å—
    - è¯†åˆ«è¯­è¨€æ ‡è®°ï¼ˆå¦‚pythonï¼‰
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "code",
    "language": "python",
    "code": "def hello():\\n    print('Hello')"
    }

    ### è¡¨æ ¼ (table)
    - Markdownè¡¨æ ¼æ ¼å¼ï¼š|åˆ—1|åˆ—2| 
    - HTMLè¡¨æ ¼æ ¼å¼ï¼š<table>...</table>
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "table",
    "headers": ["Column 1", "Column 2"],
    "rows": [
        ["Cell 1", "Cell 2"],
        ["Cell 3", "Cell 4"]
    ]
    }

    ### å¼•ç”¨ (quote)
    - ä»¥ > å¼€å¤´çš„è¡Œ
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {
    "type": "quote",
    "content": {
        "en": [{"type": "text", "content": "This is a quote"}]
    }
    }

    ### åˆ†å‰²çº¿ (divider)
    - ---, ***, ___ ç­‰
    - è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
    {"type": "divider"}

    ## ç‰¹æ®Šå¤„ç†è§„åˆ™

    ### å¼•ç”¨åˆ é™¤
    **å®Œå…¨åˆ é™¤**è„šæ³¨æ ‡è®°ï¼šå¦‚ [^1], [^note]ä¸è¦åŒ…å«åœ¨è¾“å‡ºä¸­

    ### æ–‡æœ¬å¤„ç†
    æ··åˆæ–‡æœ¬å’Œå…¬å¼æ—¶ï¼Œå°†å…¬å¼è¯†åˆ«ä¸ºinline-mathç±»å‹ã€‚ä¾‹å¦‚ï¼š
    è¾“å…¥ï¼š"The equation $x^2 + y^2 = z^2$ represents..."
    è¾“å‡ºï¼š[
    {"type": "text", "content": "The equation "},
    {"type": "inline-math", "latex": "x^2 + y^2 = z^2"},
    {"type": "text", "content": " represents..."}
    ]

    ## å®Œæ•´ç¤ºä¾‹

    è¾“å…¥Markdownï¼š
    ## Introduction

    Machine learning has revolutionized many fields. The basic equation $y = wx + b$ represents a linear model.

    $$
    L = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 \\tag{1}
    $$

    Key advantages include:
    - High accuracy
    - Fast processing

    | Method | Accuracy |
    |--------|----------|
    | SVM    | 95%      |
    | CNN    | 98%      |

    è¾“å‡ºJSONï¼š
    [
    {
        "type": "heading",
        "level": 2,
        "content": {
        "en": [{"type": "text", "content": "Introduction"}]
        }
    },
    {
        "type": "paragraph",
        "content": {
        "en": [
            {"type": "text", "content": "Machine learning has revolutionized many fields. The basic equation "},
            {"type": "inline-math", "latex": "y = wx + b"},
            {"type": "text", "content": " represents a linear model."}
        ]
        }
    },
    {
        "type": "math",
        "latex": "L = \\\\frac{1}{n}\\\\sum_{i=1}^{n}(y_i - \\\\hat{y}_i)^2"
    },
    {
        "type": "paragraph",
        "content": {
        "en": [{"type": "text", "content": "Key advantages include:"}]
        }
    },
    {
        "type": "unordered-list",
        "items": [
        {"content": {"en": [{"type": "text", "content": "High accuracy"}]}},
        {"content": {"en": [{"type": "text", "content": "Fast processing"}]}}
        ]
    },
    {
        "type": "table",
        "headers": ["Method", "Accuracy"],
        "rows": [
        ["SVM", "95%"],
        ["CNN", "98%"]
        ]
    }
    ]
    è¦æ±‚ï¼š
    - æ‰€æœ‰å‡ºç°åœ¨ JSON å­—ç¬¦ä¸²ä¸­çš„åŒå¼•å· " å¿…é¡»å†™æˆ \"ã€‚
    - å¦‚æœæ˜¯è‡ªç„¶è¯­è¨€ä¸­çš„å¼•å·ï¼Œä¼˜å…ˆä½¿ç”¨å•å¼•å· ' è€Œä¸æ˜¯åŒå¼•å· "ã€‚
    - æ‰€æœ‰ LaTeX å…¬å¼åªèƒ½å‡ºç°åœ¨ "latex" å­—æ®µä¸­ï¼Œä¸èƒ½ç›´æ¥æ”¾åœ¨ content æ–‡æœ¬å­—ç¬¦ä¸²é‡Œã€‚
    - content å­—ç¬¦ä¸²ä¸­ç¦æ­¢å‡ºç°æœªè½¬ä¹‰çš„åæ–œæ  \ï¼Œå¦‚æœ‰éœ€è¦è¯·ä½¿ç”¨ \\ã€‚
    ## é‡è¦æé†’
    1. **åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹**
    2. **inline-mathå¿…é¡»ç”¨latexå­—æ®µï¼Œä¸èƒ½ç”¨contentå­—æ®µ**
    3. **åˆ é™¤æ‰€æœ‰å¼•ç”¨æ ‡è®°**
    4. **ä¿æŒå­¦æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§**
    5. JSON ä¸­çš„å­—ç¬¦ä¸²å¿…é¡»æ˜¯åˆæ³• JSON å­—ç¬¦ä¸²ï¼Œæ‰€æœ‰å†…éƒ¨çš„åŒå¼•å·è¦å†™æˆ \"ï¼Œåæ–œæ å†™æˆ \\ã€‚
    6. ä¸è¦åœ¨ JSON å¤–è¾“å‡ºä»»ä½•è§£é‡Šæ–‡å­—
    """

        TRANSLATION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç¿»è¯‘ä¸“å®¶ã€‚

## ä»»åŠ¡
å°†æä¾›çš„JSONæ•°ç»„ä¸­çš„è‹±æ–‡å†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œæ·»åŠ åˆ°zhå­—æ®µä¸­ã€‚

## ç¿»è¯‘è¦æ±‚
1. ä¿æŒå­¦æœ¯æœ¯è¯­çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
2. æ•°å­¦å…¬å¼ã€ä»£ç ã€å˜é‡åç­‰ä¿æŒåŸæ ·
3. ä½¿ç”¨è§„èŒƒçš„å­¦æœ¯ä¸­æ–‡è¡¨è¾¾
4. ä¿æŒåŸæ–‡çš„è¯­ä¹‰å’Œé€»è¾‘ç»“æ„

## è¾“å…¥æ ¼å¼
ä½ ä¼šæ”¶åˆ°ä¸€ä¸ªåŒ…å«è‹±æ–‡å†…å®¹çš„JSONæ•°ç»„ã€‚

## è¾“å‡ºæ ¼å¼
è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªåŒ…å«contentå­—æ®µçš„å¯¹è±¡éƒ½åº”è¯¥åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªå­—æ®µã€‚

**é‡è¦**ï¼šåªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—ã€‚"""

        # ä½¿ç”¨å…¨å±€çš„safe_printå‡½æ•°ï¼Œé¿å…é‡å¤å®šä¹‰

        def _parse_markdown_stream():
            """ä½¿ç”¨LLMæµå¼è§£æMarkdownæ–‡æœ¬"""
            safe_print("ğŸš€ å¼€å§‹æµå¼è§£æMarkdownæ–‡æœ¬")
            yield {"type": "progress", "stage": "parsing", "message": "å¼€å§‹è§£ææ–‡æœ¬å†…å®¹...", "progress": 10}
            
            # é¢„å¤„ç†ï¼šæ¸…ç†æ–‡æœ¬
            cleaned_text = text.strip()
            
            # æ›¿æ¢è¡Œå†…å…¬å¼æ ¼å¼ $...$ -> \(...\)
            cleaned_text = re.sub(r'\$([^$]+)\$', r'\\(\1\\)', cleaned_text)
            
            # æ›¿æ¢è¡Œé—´å…¬å¼æ ¼å¼ $...$ -> \\[...\\]
            cleaned_text = re.sub(r'\$\$([^$]+)\$\$', r'\\[\1\\]', cleaned_text, flags=re.DOTALL)
            cleaned_text = cleaned_text.replace('"', "'")
            # é™åˆ¶æ–‡æœ¬é•¿åº¦
            if len(cleaned_text) > 30000:
                safe_print(f"âš ï¸ æ–‡æœ¬è¿‡é•¿({len(cleaned_text)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³30000å­—ç¬¦")
                cleaned_text = cleaned_text[:30000]
                yield {"type": "progress", "stage": "parsing", "message": "æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­å¤„ç†", "progress": 15}
            
            user_prompt = f"""è¯·è§£æä»¥ä¸‹Markdownæ ¼å¼çš„å­¦æœ¯è®ºæ–‡æ–‡æœ¬ï¼Œè¾“å‡ºJSONæ•°ç»„ï¼š

{cleaned_text}

è®°ä½ï¼š
1. åªè¾“å‡ºJSONæ•°ç»„
2. åˆ é™¤æ‰€æœ‰å¼•ç”¨
3. inline-mathä½¿ç”¨latexå­—æ®µ
4. å»é™¤å…¬å¼ç¼–å·å¦‚\\tag{{}}
5. **é‡è¦ï¼šå¿…é¡»åŒæ—¶åŒ…å«ä¸­è‹±æ–‡å†…å®¹ï¼Œæ¯ä¸ªblockçš„contentå­—æ®µå¿…é¡»åŒæ—¶åŒ…å«enå’Œzhä¸¤ä¸ªè¯­è¨€æ•°ç»„**"""

            messages = [
                {"role": "system", "content": PARSER_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            safe_print("ğŸ“¤ å‘é€æµå¼è§£æè¯·æ±‚...")
            yield {"type": "progress", "stage": "parsing", "message": "æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è§£ææ–‡æœ¬...", "progress": 20}
            
            # æ”¶é›†æµå¼å“åº”ï¼ŒåŒæ—¶ä¼ é€’GLMçš„åŸå§‹æ•°æ®
            full_content = ""
            content_preview = ""  # ç”¨äºç”Ÿæˆè¿›åº¦æ¶ˆæ¯çš„å†…å®¹é¢„è§ˆ
            last_progress_update = 0  # è®°å½•ä¸Šæ¬¡è¿›åº¦æ›´æ–°çš„å†…å®¹é•¿åº¦ï¼Œé¿å…é¢‘ç¹æ›´æ–°
            
            for chunk in self.call_llm_stream(messages, temperature=0.1, max_tokens=50000):
                if "error" in chunk:
                    yield {"type": "error", "message": chunk["error"]}
                    return
                
                if chunk.get("type") == "glm_stream":
                    # ç›´æ¥ä¼ é€’GLMçš„åŸå§‹æµå¼æ•°æ®åˆ°å‰ç«¯
                    yield {
                        "type": "glm_stream",
                        "raw_data": chunk["raw_data"],
                        "content": chunk["content"],
                        "model": chunk["model"],
                        "usage": chunk["usage"]
                    }
                    
                    # åŒæ—¶æ”¶é›†å†…å®¹ç”¨äºåç»­è§£æ
                    full_content += chunk["content"]
                    content_preview += chunk["content"]
                    
                    # è®¡ç®—è¿›åº¦ï¼ˆè§£æé˜¶æ®µç°åœ¨å æ€»è¿›åº¦çš„90%ï¼Œå› ä¸ºåŒ…å«ç¿»è¯‘ä¸”ä¸å†æœ‰å•ç‹¬ç¿»è¯‘æ­¥éª¤ï¼‰
                    progress = min(20 + int(len(full_content) / 50), 90)
                    
                    # æ ¹æ®å†…å®¹ç”Ÿæˆæ›´è¯¦ç»†çš„è¿›åº¦æ¶ˆæ¯
                    # åªæœ‰å½“å†…å®¹å¢é•¿è¶…è¿‡ä¸€å®šé‡æ—¶æ‰æ›´æ–°æ¶ˆæ¯ï¼Œé¿å…è¿‡äºé¢‘ç¹
                    if len(full_content) - last_progress_update > 100 or progress % 10 == 0:
                        last_progress_update = len(full_content)
                        
                        # ç”ŸæˆåŸºäºå†…å®¹çš„è¿›åº¦æ¶ˆæ¯
                        if len(content_preview.strip()) > 0:
                            # è·å–æœ€æ–°çš„å†…å®¹ç‰‡æ®µç”¨äºç”Ÿæˆè¿›åº¦æ¶ˆæ¯
                            preview_text = content_preview.strip()[-200:] if len(content_preview.strip()) > 200 else content_preview.strip()
                            
                            # æ ¹æ®å†…å®¹ç‰¹å¾ç”Ÿæˆä¸åŒçš„è¿›åº¦æ¶ˆæ¯
                            if progress < 30:
                                message = f"å¼€å§‹è§£ææ–‡æœ¬å†…å®¹...å·²æ¥æ”¶ {len(full_content)} å­—ç¬¦"
                            elif progress < 60:
                                # å°è¯•è¯†åˆ«å†…å®¹ç±»å‹
                                if any(keyword in preview_text.lower() for keyword in ['abstract', 'æ‘˜è¦', 'introduction', 'å¼•è¨€', 'background', 'èƒŒæ™¯']):
                                    message = f"æ­£åœ¨è§£æè®ºæ–‡æ‘˜è¦å’Œå¼•è¨€éƒ¨åˆ†...({progress}%)"
                                elif any(keyword in preview_text.lower() for keyword in ['method', 'æ–¹æ³•', 'approach', 'æ–¹æ³•', 'experiment', 'å®éªŒ']):
                                    message = f"æ­£åœ¨è§£ææ–¹æ³•å’Œå®éªŒéƒ¨åˆ†...({progress}%)"
                                else:
                                    message = f"æ­£åœ¨è§£æè®ºæ–‡ä¸»ä½“å†…å®¹...({progress}%)"
                            elif progress < 85:
                                # å°è¯•è¯†åˆ«æ›´å¤šå†…å®¹ç±»å‹
                                if any(keyword in preview_text.lower() for keyword in ['result', 'ç»“æœ', 'conclusion', 'ç»“è®º', 'discussion', 'è®¨è®º']):
                                    message = f"æ­£åœ¨è§£æç»“æœå’Œç»“è®ºéƒ¨åˆ†...({progress}%)"
                                elif any(keyword in preview_text.lower() for keyword in ['table', 'è¡¨æ ¼', 'figure', 'å›¾', 'chart', 'å›¾è¡¨']):
                                    message = f"æ­£åœ¨è§£æè¡¨æ ¼å’Œå›¾è¡¨å†…å®¹...({progress}%)"
                                else:
                                    message = f"ç»§ç»­è§£æè®ºæ–‡å†…å®¹...({progress}%)"
                            else:
                                message = f"å³å°†å®Œæˆè§£æ...({progress}%)"
                            
                            # å¦‚æœå†…å®¹ä¸­åŒ…å«JSONç»“æ„ï¼Œè¯´æ˜æ­£åœ¨ç”Ÿæˆç»“æ„åŒ–æ•°æ®
                            if '{' in preview_text and '}' in preview_text and ('type' in preview_text or '"content"' in preview_text):
                                message = f"æ­£åœ¨ç”Ÿæˆç»“æ„åŒ–å†…å®¹...({progress}%)"
                        else:
                            message = f"æ­£åœ¨è§£æå’Œç¿»è¯‘æ–‡æœ¬å†…å®¹...({progress}%)"
                        
                        yield {"type": "progress", "stage": "parsing", "message": message, "progress": progress}
                        
                elif "content" in chunk:
                    # å…¼å®¹æ—§æ ¼å¼
                    full_content += chunk["content"]
                    content_preview += chunk["content"]
                    progress = min(20 + int(len(full_content) / 50), 90)
                    
                    # æ ¹æ®å†…å®¹ç”Ÿæˆæ›´è¯¦ç»†çš„è¿›åº¦æ¶ˆæ¯
                    if len(full_content) - last_progress_update > 100 or progress % 10 == 0:
                        last_progress_update = len(full_content)
                        message = f"æ­£åœ¨è§£æå’Œç¿»è¯‘æ–‡æœ¬å†…å®¹...({progress}%)"
                        yield {"type": "progress", "stage": "parsing", "message": message, "progress": progress}
            
            # æ¸…ç†å“åº”å†…å®¹
            content = full_content.strip()
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            elif "```" in content:
                start = content.find("```") + 3
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            
            try:
                blocks = json.loads(content)
                safe_print(f"âœ… è§£æå®Œæˆï¼Œå¾—åˆ° {len(blocks)} ä¸ªblocks")
                yield {"type": "progress", "stage": "parsing", "message": f"è§£æå’Œç¿»è¯‘å®Œæˆï¼Œå¾—åˆ° {len(blocks)} ä¸ªå†…å®¹å—", "progress": 90}
                return blocks
            except json.JSONDecodeError as e:
                safe_print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                safe_print(f"å“åº”å†…å®¹: {content[:500]}...")
                
                # ä¿å­˜é”™è¯¯å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
                import os
                import traceback
                from datetime import datetime
                
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ç›®å½•ä½ç½®
                possible_dirs = [
                    "error_logs",
                    "apps/api/error_logs",
                    "apps/api/neuink/error_logs",
                    "/tmp/error_logs" if os.name != 'nt' else "C:\\temp\\error_logs"
                ]
                
                error_dir = None
                for dir_path in possible_dirs:
                    try:
                        if not os.path.exists(dir_path):
                            os.makedirs(dir_path, exist_ok=True)
                        # æµ‹è¯•æ˜¯å¦å¯ä»¥å†™å…¥
                        test_file = os.path.join(dir_path, "test_write.tmp")
                        with open(test_file, 'w') as f:
                            f.write("test")
                        os.remove(test_file)
                        error_dir = dir_path
                        safe_print(f"âœ… ä½¿ç”¨é”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                        break
                    except Exception as dir_error:
                        safe_print(f"âš ï¸ æ— æ³•ä½¿ç”¨ç›®å½• {dir_path}: {dir_error}")
                        continue
                
                if not error_dir:
                    # å¦‚æœæ‰€æœ‰é¢„è®¾ç›®å½•éƒ½ä¸å¯ç”¨ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•åˆ›å»º
                    try:
                        error_dir = os.getcwd()
                        safe_print(f"âš ï¸ ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºé”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                    except Exception as cwd_error:
                        safe_print(f"âŒ æ— æ³•è·å–å½“å‰ç›®å½•: {cwd_error}")
                        error_dir = "."
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                error_file = os.path.join(error_dir, f"json_parse_error_stream_{timestamp}.txt")
                
                try:
                    with open(error_file, 'w', encoding='utf-8') as f:
                        f.write(f"æµå¼JSONè§£æé”™è¯¯æ—¶é—´: {datetime.now()}\n")
                        f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                        f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                        f.write(f"é”™è¯¯ä½ç½®: line {e.lineno}, column {e.colno}, character {e.pos}\n")
                        f.write(f"é”™è¯¯è¯¦æƒ…: {e.msg if hasattr(e, 'msg') else 'æ— è¯¦ç»†ä¿¡æ¯'}\n")
                        f.write("=" * 50 + "\n")
                        f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                        f.write(content)
                        f.write("\n" + "=" * 50 + "\n")
                        f.write(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\n")
                        f.write(f"å‰500å­—ç¬¦é¢„è§ˆ: {content[:500]}\n")
                        f.write(f"å500å­—ç¬¦é¢„è§ˆ: {content[-500:] if len(content) > 500 else 'æ— '}\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("é”™è¯¯ä½ç½®ä¸Šä¸‹æ–‡:\n")
                        if hasattr(e, 'pos') and e.pos is not None:
                            start_pos = max(0, e.pos - 100)
                            end_pos = min(len(content), e.pos + 100)
                            f.write(f"ä½ç½® {e.pos} é™„è¿‘å†…å®¹:\n")
                            f.write(repr(content[start_pos:end_pos]))
                            f.write("\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("å®Œæ•´å †æ ˆè·Ÿè¸ª:\n")
                        f.write(traceback.format_exc())
                    safe_print(f"âœ… æµå¼é”™è¯¯å†…å®¹å·²ä¿å­˜åˆ°: {error_file}")
                    
                    # å°è¯•åœ¨Windowsæ¡Œé¢ä¹Ÿä¿å­˜ä¸€ä»½
                    try:
                        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
                        if os.path.exists(desktop_path):
                            desktop_error_file = os.path.join(desktop_path, f"neuink_stream_json_error_{timestamp}.txt")
                            with open(desktop_error_file, 'w', encoding='utf-8') as f:
                                f.write(f"NeuInk æµå¼JSONè§£æé”™è¯¯ - {datetime.now()}\n")
                                f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                                f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                                f.write("=" * 50 + "\n")
                                f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                                f.write(content)
                            safe_print(f"âœ… æµå¼é”™è¯¯å‰¯æœ¬å·²ä¿å­˜åˆ°æ¡Œé¢: {desktop_error_file}")
                    except Exception as desktop_error:
                        safe_print(f"âš ï¸ æ— æ³•ä¿å­˜åˆ°æ¡Œé¢: {desktop_error}")
                        
                except Exception as save_error:
                    safe_print(f"âŒ ä¿å­˜æµå¼é”™è¯¯æ—¥å¿—å¤±è´¥: {save_error}")
                    safe_print(f"âŒ å°è¯•ä¿å­˜çš„è·¯å¾„: {error_file}")
                    safe_print(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
                yield {"type": "error", "message": f"è§£æå¤±è´¥ï¼ŒJSONæ ¼å¼é”™è¯¯: {e}"}
                return None

        def _add_translations_stream(blocks):
            """ä¸ºblocksæµå¼æ·»åŠ ä¸­æ–‡ç¿»è¯‘ - å·²ä¼˜åŒ–ï¼šè§£ææ­¥éª¤å·²åŒ…å«ç¿»è¯‘ï¼Œæ­¤å‡½æ•°ç°åœ¨åªåšéªŒè¯"""
            if not blocks:
                return blocks
                
            safe_print("ğŸŒ éªŒè¯ç¿»è¯‘å†…å®¹ï¼ˆè§£ææ­¥éª¤å·²åŒ…å«ç¿»è¯‘ï¼‰")
            yield {"type": "progress", "stage": "validating_translations", "message": "éªŒè¯ç¿»è¯‘å®Œæ•´æ€§...", "progress": 92}
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å…¨ç¿»è¯‘
            needs_completion = False
            for block in blocks:
                if "content" in block and isinstance(block["content"], dict):
                    if "en" in block["content"] and not block["content"].get("zh"):
                        # å¦‚æœæœ‰è‹±æ–‡ä½†æ²¡æœ‰ä¸­æ–‡ï¼Œå¤åˆ¶è‹±æ–‡å†…å®¹ä½œä¸ºä¸­æ–‡
                        block["content"]["zh"] = block["content"]["en"].copy()
                        needs_completion = True
                    elif "zh" in block["content"] and not block["content"].get("en"):
                        # å¦‚æœæœ‰ä¸­æ–‡ä½†æ²¡æœ‰è‹±æ–‡ï¼Œå¤åˆ¶ä¸­æ–‡å†…å®¹ä½œä¸ºè‹±æ–‡
                        block["content"]["en"] = block["content"]["zh"].copy()
                        needs_completion = True
            
            if needs_completion:
                safe_print("âœ… è¡¥å…¨äº†ç¼ºå¤±çš„ç¿»è¯‘å†…å®¹")
                yield {"type": "progress", "stage": "validating_translations", "message": "è¡¥å…¨ç¼ºå¤±çš„ç¿»è¯‘å†…å®¹", "progress": 95}
            else:
                safe_print("âœ… æ‰€æœ‰å†…å®¹ç¿»è¯‘å®Œæ•´")
                yield {"type": "progress", "stage": "validating_translations", "message": "ç¿»è¯‘å†…å®¹å®Œæ•´", "progress": 95}
            
            return blocks

        def _fix_and_validate_stream(blocks):
            """æµå¼ä¿®å¤å’ŒéªŒè¯blocks"""
            if not blocks:
                return blocks
                
            safe_print("ğŸ”§ å¼€å§‹æµå¼ä¿®å¤å’ŒéªŒè¯blocks")
            yield {"type": "progress", "stage": "validating", "message": "å¼€å§‹éªŒè¯å’Œä¿®å¤å†…å®¹æ ¼å¼...", "progress": 90}
            
            # å¯¼å…¥å¿…è¦çš„å·¥å…·å‡½æ•°
            try:
                from ..utils.common import generate_id, get_current_time
            except ImportError:
                # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                import uuid
                from datetime import datetime
                
                def generate_id():
                    return str(uuid.uuid4())
                
                def get_current_time():
                    return datetime.now()
            
            validated_blocks = []
            
            for idx, block in enumerate(blocks):
                try:
                    if not isinstance(block, dict) or "type" not in block:
                        safe_print(f"â­ï¸ è·³è¿‡æ— æ•ˆblock {idx}: ç¼ºå°‘typeå­—æ®µ")
                        continue
                    
                    # æ·»åŠ å¿…éœ€å­—æ®µ
                    if "id" not in block:
                        block["id"] = generate_id()
                    if "createdAt" not in block:
                        block["createdAt"] = get_current_time().isoformat()
                    
                    # ç¡®ä¿contentå­—æ®µæ ¼å¼æ­£ç¡®
                    if "content" in block:
                        content = block["content"]
                        if isinstance(content, dict):
                            # ç¡®ä¿æœ‰enå’Œzhå­—æ®µ
                            if "en" not in content:
                                content["en"] = []
                            if "zh" not in content:
                                # å¦‚æœæ²¡æœ‰zhå­—æ®µï¼Œå¤åˆ¶ençš„å†…å®¹
                                content["zh"] = content.get("en", []).copy()
                            
                            # ä¿®å¤inline-mathå­—æ®µ
                            for lang in ["en", "zh"]:
                                if lang in content and isinstance(content[lang], list):
                                    for item in content[lang]:
                                        if isinstance(item, dict) and item.get("type") == "inline-math":
                                            # ç¡®ä¿ä½¿ç”¨latexå­—æ®µè€Œä¸æ˜¯contentå­—æ®µ
                                            if "content" in item and "latex" not in item:
                                                item["latex"] = item.pop("content")
                                                safe_print(f"ğŸ”§ ä¿®å¤block {idx} çš„inline-mathå­—æ®µ")
                    
                    # å¤„ç†åˆ—è¡¨é¡¹
                    if block["type"] in ["ordered-list", "unordered-list"]:
                        if "items" in block and isinstance(block["items"], list):
                            for item_idx, item in enumerate(block["items"]):
                                if "content" in item and isinstance(item["content"], dict):
                                    # ç¡®ä¿åˆ—è¡¨é¡¹ä¹Ÿæœ‰åŒè¯­å†…å®¹
                                    if "en" not in item["content"]:
                                        item["content"]["en"] = []
                                    if "zh" not in item["content"]:
                                        item["content"]["zh"] = item["content"].get("en", []).copy()
                                    
                                    # ä¿®å¤åˆ—è¡¨é¡¹ä¸­çš„inline-math
                                    for lang in ["en", "zh"]:
                                        if lang in item["content"] and isinstance(item["content"][lang], list):
                                            for content_item in item["content"][lang]:
                                                if isinstance(content_item, dict) and content_item.get("type") == "inline-math":
                                                    if "content" in content_item and "latex" not in content_item:
                                                        content_item["latex"] = content_item.pop("content")
                    
                    # å¤„ç†è¡¨æ ¼
                    if block["type"] == "table":
                        # ç¡®ä¿è¡¨æ ¼æœ‰å¿…è¦çš„å­—æ®µ
                        if "headers" not in block:
                            block["headers"] = []
                        if "rows" not in block:
                            block["rows"] = []
                        # è¡¨æ ¼çš„captionä¹Ÿéœ€è¦åŒè¯­
                        if "caption" in block and isinstance(block["caption"], dict):
                            if "en" not in block["caption"]:
                                block["caption"]["en"] = []
                            if "zh" not in block["caption"]:
                                block["caption"]["zh"] = block["caption"].get("en", []).copy()
                    
                    # å¤„ç†æ•°å­¦å…¬å¼å—
                    if block["type"] == "math":
                        if "latex" in block:
                            # å»é™¤\tag{}ç¼–å·
                            latex = block["latex"]
                            latex = re.sub(r'\\tag\{[^}]*\}', '', latex)
                            # å»é™¤å¤šä½™çš„ç©ºæ ¼
                            latex = re.sub(r'\s+', ' ', latex).strip()
                            block["latex"] = latex
                    
                    validated_blocks.append(block)
                    safe_print(f"âœ… éªŒè¯block {idx}: type={block['type']}")
                    
                except Exception as e:
                    safe_print(f"âŒ éªŒè¯block {idx} å¤±è´¥: {e}")
                    continue
            
            safe_print(f"âœ… æœ€ç»ˆç”Ÿæˆ {len(validated_blocks)} ä¸ªæœ‰æ•ˆblocks")
            yield {"type": "progress", "stage": "validating", "message": f"éªŒè¯å®Œæˆï¼Œç”Ÿæˆ {len(validated_blocks)} ä¸ªæœ‰æ•ˆå†…å®¹å—", "progress": 95}
            return validated_blocks

        # ä¸»æ‰§è¡Œæµç¨‹
        try:
            # æ­¥éª¤1ï¼šè§£æMarkdownï¼ˆç°åœ¨åŒ…å«ç¿»è¯‘ï¼‰
            blocks = yield from _parse_markdown_stream()
            if blocks is None:
                return
            
            # æ­¥éª¤2ï¼šä¿®å¤å’ŒéªŒè¯
            validated_blocks = yield from _fix_and_validate_stream(blocks)
            if validated_blocks is None:
                return
            
            # å®Œæˆ
            yield {"type": "complete", "message": f"è§£æå®Œæˆï¼Œå…±ç”Ÿæˆ {len(validated_blocks)} ä¸ªå†…å®¹å—", "blocks": validated_blocks, "progress": 100}
            
        except Exception as e:
            safe_print(f"âŒ æµå¼å¤„ç†å¤±è´¥: {e}")
            import traceback
            safe_print(traceback.format_exc())
            yield {"type": "error", "message": f"æµå¼è§£æå¤±è´¥: {e}"}

    def parse_references(self, text: str) -> List[Dict[str, Any]]:
            """
            è§£æå‚è€ƒæ–‡çŒ®æ–‡æœ¬ï¼Œè¿”å›ç»“æ„åŒ–çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            
            Args:
                text: å‚è€ƒæ–‡çŒ®æ–‡æœ¬ï¼Œå¯èƒ½åŒ…å«å¤šæ¡å‚è€ƒæ–‡çŒ®
                
            Returns:
                è§£æåçš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œæ¯æ¡å‚è€ƒæ–‡çŒ®åŒ…å«æ ‡å‡†å­—æ®µ
            """
            safe_print("=" * 60)
            safe_print("å¼€å§‹è§£æå‚è€ƒæ–‡çŒ®")
            safe_print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            safe_print("=" * 60)
            
            # æ£€æŸ¥APIå¯†é’¥
            if not self.glm_api_key or self.glm_api_key == "your_glm_api_key_here":
                error_msg = "LLMæœåŠ¡ä¸å¯ç”¨ï¼šæœªé…ç½®GLM_API_KEYæˆ–ä½¿ç”¨äº†å ä½ç¬¦å€¼ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„GLM APIå¯†é’¥ã€‚"
                safe_print(error_msg)
                raise RuntimeError(error_msg)
            
            try:
                return self._parse_references_with_llm(text)
            except Exception as e:
                error_msg = f"å‚è€ƒæ–‡çŒ®è§£æå¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼Œæˆ–ç¨åé‡è¯•ã€‚"
                safe_print(error_msg)
                raise RuntimeError(error_msg)
        
    def _parse_references_with_llm(self, text: str) -> List[Dict[str, Any]]:
            """ä½¿ç”¨LLMè§£æå‚è€ƒæ–‡çŒ®"""
            import json
            import re
            
            # é™åˆ¶æ–‡æœ¬é•¿åº¦ä»¥é¿å…è¶…å‡ºtokené™åˆ¶
            truncated_text = text[:50000] if len(text) > 50000 else text
            safe_print(f"ğŸ” åŸå§‹æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            safe_print(f"ğŸ“ è§£ææ–‡æœ¬é•¿åº¦: {len(truncated_text)} å­—ç¬¦")
            if len(text) > 50000:
                safe_print("âš ï¸  æ–‡æœ¬è¢«æˆªæ–­ï¼Œå‰50,000å­—ç¬¦å°†è¢«è§£æ")
            
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯å‚è€ƒæ–‡çŒ®è§£æåŠ©æ‰‹ã€‚è¯·ä»ç»™å®šçš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬ä¸­è§£æå‡ºæ¯ä¸€æ¡å‚è€ƒæ–‡çŒ®ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ã€‚

    **ä»»åŠ¡è¦æ±‚ï¼š**
    1. è¯†åˆ«å¹¶åˆ†ç¦»æ¯ä¸€æ¡å‚è€ƒæ–‡çŒ®
    2. æå–æ¯æ¡å‚è€ƒæ–‡çŒ®çš„ä»¥ä¸‹ä¿¡æ¯ï¼š
    - authors: ä½œè€…åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰
    - title: è®ºæ–‡æ ‡é¢˜
    - publication: å‘è¡¨æœŸåˆŠ/ä¼šè®®åç§°
    - year: å‘è¡¨å¹´ä»½ï¼ˆæ•´æ•°ï¼‰
    - volume: å·å·ï¼ˆå¦‚æœæœ‰ï¼‰
    - issue: æœŸå·ï¼ˆå¦‚æœæœ‰ï¼‰
    - pages: é¡µç ï¼ˆå¦‚æœæœ‰ï¼‰
    - doi: DOIï¼ˆå¦‚æœæœ‰ï¼‰
    - url: URLé“¾æ¥ï¼ˆå¦‚æœæœ‰ï¼‰
    - type: æ–‡çŒ®ç±»å‹ï¼ˆjournal/conference/preprint/book/thesisç­‰ï¼‰

    **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
    1. å¿…é¡»è¿”å›ä¸€ä¸ªæœ‰æ•ˆçš„JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€æ¡å‚è€ƒæ–‡çŒ®
    2. å¦‚æœæŸäº›å­—æ®µæ— æ³•æå–ï¼Œè¯·è®¾ç½®ä¸ºnullæˆ–çœç•¥
    3. ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²å€¼éƒ½ç»è¿‡é€‚å½“çš„trimå¤„ç†
    4. ä¿æŒåŸå§‹æ•°æ®çš„å‡†ç¡®æ€§ï¼Œä¸è¦æ·»åŠ æˆ–ä¿®æ”¹å†…å®¹

    **å‚è€ƒæ–‡çŒ®æ ¼å¼ç¤ºä¾‹ï¼š**
    - [1] J. Smith, "Title of paper," Journal Name, vol. 10, no. 2, pp. 123-145, 2020.
    - [2] K. Johnson et al., "Another paper title," Conference Name, 2019.
    - [3] L. Wang, "Book title," Publisher, 2018.

    è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–æ³¨é‡Šã€‚"""

            user_prompt = f"""è¯·è§£æä»¥ä¸‹å‚è€ƒæ–‡çŒ®æ–‡æœ¬ï¼Œæå–æ¯æ¡å‚è€ƒæ–‡çŒ®çš„è¯¦ç»†ä¿¡æ¯ï¼š

    {truncated_text}

    è¯·è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€æ¡è§£æåçš„å‚è€ƒæ–‡çŒ®ã€‚"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            try:
                safe_print("ğŸ“¤ å‘é€å‚è€ƒæ–‡çŒ®è§£æè¯·æ±‚åˆ°LLM...")
                response = self.call_llm(messages, temperature=0.1, max_tokens=100000)
                
                if not response or "choices" not in response:
                    safe_print("âŒ LLMå“åº”æ ¼å¼é”™è¯¯")
                    raise Exception("LLMå“åº”æ ¼å¼é”™è¯¯")
                    
                content = response["choices"][0]["message"]["content"]
                safe_print(f"ğŸ’¬ LLMåŸå§‹å“åº”: {content[:500]}...")
                
                # æå–JSONå†…å®¹
                if "```json" in content:
                    fence = "```json"
                    start = content.find(fence) + len(fence)
                    end = content.find("```", start)
                    content = content[start:end].strip()
                elif "```" in content:
                    fence = "```"
                    start = content.find(fence) + len(fence)
                    end = content.find("```", start)
                    content = content[start:end].strip()
                
                # æ¸…ç†å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
                content = content.strip()
                if content.startswith('json'):
                    content = content[4:].strip()
                
                safe_print(f"ğŸ”„ è§£æJSONå†…å®¹: {content[:200]}...")
                parsed_references = json.loads(content)
                
                # ç¡®ä¿è¿”å›çš„æ˜¯æ•°ç»„
                if not isinstance(parsed_references, list):
                    safe_print("âŒ LLMè¿”å›çš„ä¸æ˜¯æ•°ç»„æ ¼å¼")
                    raise Exception("LLMè¿”å›çš„ä¸æ˜¯æ•°ç»„æ ¼å¼")
                
                # ä¸ºæ¯æ¡å‚è€ƒæ–‡çŒ®æ·»åŠ IDå¹¶éªŒè¯æ ¼å¼
                from ..utils.common import generate_id
                validated_references = []
                
                for i, ref in enumerate(parsed_references):
                    if not isinstance(ref, dict):
                        safe_print(f"â­ï¸  è·³è¿‡æ— æ•ˆå‚è€ƒæ–‡çŒ®: {ref}")
                        continue
                    
                    # ç¡®ä¿æœ‰æ ‡é¢˜
                    if not ref.get("title"):
                        safe_print(f"â­ï¸  è·³è¿‡æ— æ ‡é¢˜å‚è€ƒæ–‡çŒ®: {ref}")
                        continue
                    
                    # æ·»åŠ ID
                    ref["id"] = generate_id()
                    
                    # ç¡®ä¿authorsæ˜¯æ•°ç»„
                    if "authors" in ref and not isinstance(ref["authors"], list):
                        if isinstance(ref["authors"], str):
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•åˆ†å‰²
                            ref["authors"] = [author.strip() for author in ref["authors"].split(",")]
                        else:
                            ref["authors"] = [str(ref["authors"])]
                    
                    validated_references.append(ref)
                    safe_print(f"âœ… éªŒè¯å‚è€ƒæ–‡çŒ® {i+1}: {ref.get('title', 'Unknown')}")
                
                safe_print(f"ğŸ‰ å®ŒæˆéªŒè¯ï¼Œç”Ÿæˆ{len(validated_references)}æ¡æœ‰æ•ˆå‚è€ƒæ–‡çŒ®")
                return validated_references
                
            except json.JSONDecodeError as e:
                safe_print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                safe_print(f"åŸå§‹å†…å®¹: {content}")
                
                # ä¿å­˜é”™è¯¯å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
                import os
                import traceback
                from datetime import datetime
                
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ç›®å½•ä½ç½®
                possible_dirs = [
                    "error_logs",
                    "apps/api/error_logs",
                    "apps/api/neuink/error_logs",
                    "/tmp/error_logs" if os.name != 'nt' else "C:\\temp\\error_logs"
                ]
                
                error_dir = None
                for dir_path in possible_dirs:
                    try:
                        if not os.path.exists(dir_path):
                            os.makedirs(dir_path, exist_ok=True)
                        # æµ‹è¯•æ˜¯å¦å¯ä»¥å†™å…¥
                        test_file = os.path.join(dir_path, "test_write.tmp")
                        with open(test_file, 'w') as f:
                            f.write("test")
                        os.remove(test_file)
                        error_dir = dir_path
                        safe_print(f"âœ… ä½¿ç”¨é”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                        break
                    except Exception as dir_error:
                        safe_print(f"âš ï¸ æ— æ³•ä½¿ç”¨ç›®å½• {dir_path}: {dir_error}")
                        continue
                
                if not error_dir:
                    # å¦‚æœæ‰€æœ‰é¢„è®¾ç›®å½•éƒ½ä¸å¯ç”¨ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•åˆ›å»º
                    try:
                        error_dir = os.getcwd()
                        safe_print(f"âš ï¸ ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºé”™è¯¯æ—¥å¿—ç›®å½•: {error_dir}")
                    except Exception as cwd_error:
                        safe_print(f"âŒ æ— æ³•è·å–å½“å‰ç›®å½•: {cwd_error}")
                        error_dir = "."
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                error_file = os.path.join(error_dir, f"references_parse_error_{timestamp}.txt")
                
                try:
                    with open(error_file, 'w', encoding='utf-8') as f:
                        f.write(f"å‚è€ƒæ–‡çŒ®JSONè§£æé”™è¯¯æ—¶é—´: {datetime.now()}\n")
                        f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                        f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                        f.write(f"é”™è¯¯ä½ç½®: line {e.lineno}, column {e.colno}, character {e.pos}\n")
                        f.write(f"é”™è¯¯è¯¦æƒ…: {e.msg if hasattr(e, 'msg') else 'æ— è¯¦ç»†ä¿¡æ¯'}\n")
                        f.write("=" * 50 + "\n")
                        f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                        f.write(content)
                        f.write("\n" + "=" * 50 + "\n")
                        f.write(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\n")
                        f.write(f"å‰500å­—ç¬¦é¢„è§ˆ: {content[:500]}\n")
                        f.write(f"å500å­—ç¬¦é¢„è§ˆ: {content[-500:] if len(content) > 500 else 'æ— '}\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("é”™è¯¯ä½ç½®ä¸Šä¸‹æ–‡:\n")
                        if hasattr(e, 'pos') and e.pos is not None:
                            start_pos = max(0, e.pos - 100)
                            end_pos = min(len(content), e.pos + 100)
                            f.write(f"ä½ç½® {e.pos} é™„è¿‘å†…å®¹:\n")
                            f.write(repr(content[start_pos:end_pos]))
                            f.write("\n")
                        f.write("\n" + "=" * 50 + "\n")
                        f.write("å®Œæ•´å †æ ˆè·Ÿè¸ª:\n")
                        f.write(traceback.format_exc())
                    safe_print(f"âœ… å‚è€ƒæ–‡çŒ®è§£æé”™è¯¯å†…å®¹å·²ä¿å­˜åˆ°: {error_file}")
                    
                    # å°è¯•åœ¨Windowsæ¡Œé¢ä¹Ÿä¿å­˜ä¸€ä»½
                    try:
                        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
                        if os.path.exists(desktop_path):
                            desktop_error_file = os.path.join(desktop_path, f"neuink_references_error_{timestamp}.txt")
                            with open(desktop_error_file, 'w', encoding='utf-8') as f:
                                f.write(f"NeuInk å‚è€ƒæ–‡çŒ®JSONè§£æé”™è¯¯ - {datetime.now()}\n")
                                f.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}\n")
                                f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
                                f.write("=" * 50 + "\n")
                                f.write("å®Œæ•´å“åº”å†…å®¹:\n")
                                f.write(content)
                            safe_print(f"âœ… å‚è€ƒæ–‡çŒ®è§£æé”™è¯¯å‰¯æœ¬å·²ä¿å­˜åˆ°æ¡Œé¢: {desktop_error_file}")
                    except Exception as desktop_error:
                        safe_print(f"âš ï¸ æ— æ³•ä¿å­˜åˆ°æ¡Œé¢: {desktop_error}")
                        
                except Exception as save_error:
                    safe_print(f"âŒ ä¿å­˜å‚è€ƒæ–‡çŒ®é”™è¯¯æ—¥å¿—å¤±è´¥: {save_error}")
                    safe_print(f"âŒ å°è¯•ä¿å­˜çš„è·¯å¾„: {error_file}")
                    safe_print(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
                raise Exception(f"å‚è€ƒæ–‡çŒ®è§£æå¤±è´¥ï¼Œæ— æ³•è§£æJSON: {e}")
            except Exception as e:
                safe_print(f"âŒ å‚è€ƒæ–‡çŒ®è§£æå¤±è´¥: {e}")
                raise Exception(f"å‚è€ƒæ–‡çŒ®è§£æå¤±è´¥: {e}")
        

# å…¨å±€å®ä¾‹
_llm_utils: Optional[LLMUtils] = None

def get_llm_utils() -> LLMUtils:
    """è·å– LLMUtils å…¨å±€å®ä¾‹"""
    global _llm_utils
    if _llm_utils is None:
        _llm_utils = LLMUtils()
    return _llm_utils